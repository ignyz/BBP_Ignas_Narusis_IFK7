{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kodo sutvarkymas pateikimui AmbersCorvayorWithUseCase-Modifikavimas su modelio issaugojimu.ipynb,",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNdVXYIrcZUAJIw5P6s39Z4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ignyz/BBP_Ignas_Narusis_IFK7/blob/main/Kodo_sutvarkymas_pateikimui_AmbersCorvayorWithUseCase_Modifikavimas_su_modelio_issaugojimu_ipynb%2C.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htdRR9lbIRXu"
      },
      "source": [
        "import cv2 \n",
        "import numpy as np\n",
        "import os\n",
        "from matplotlib import pyplot as plt\n",
        "import pickle\n",
        " \n",
        "##############################################\n",
        "#         Kodo importavimo vieta\n",
        " \n",
        "import natsort \n",
        "from datetime import datetime\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics import silhouette_samples, siluetoTaskai\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import numpy as np\n",
        "import matplotlib.style as style\n",
        " \n",
        "##############################################\n",
        "\n",
        "import json\n",
        "import ast\n",
        "\n",
        "import time\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import os, psutil\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import itertools\n",
        "import gc\n",
        "import cv2 \n",
        " \n",
        "import skimage\n",
        "import sklearn\n",
        "from sklearn.decomposition import PCA \n",
        "from sklearn.feature_extraction import nuotrauka\n",
        "from skimage.segmentation import chan_vese\n",
        "from skimage.morphology import closing, square, disk\n",
        "from skimage.io import imread\n",
        "from skimage.filters import rank, threshold_otsu\n",
        "from skimage.feature import canny\n",
        "from skimage.color import rgb2grey\n",
        "from skimage.color import rgb2gray\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from skimage import exposure as hist, data, img_as_float\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.svm import SVR\n",
        "\n",
        "import scipy.stats as stats\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.spatial import distance\n",
        "from scipy.ndimage.interpolation import rotate\n",
        "from scipy import spatial\n",
        "from scipy import ndimage as ndi \n",
        "from scipy import ndimage\n",
        "from matplotlib import pyplot as plt\n",
        "from glob import glob\n",
        "from PIL import ImageTk\n",
        "from PIL import Image, TiffImagePlugin\n",
        "from PIL import Image as Img\n",
        "from PIL import Image\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import json\n",
        "\n",
        "##############################################\n",
        "#   SOM bibliotekos įdiegimas\n",
        "\n",
        "!pip install sklearn-som\n",
        "from sklearn_som.som import SOM\n",
        "from sklearn import datasets\n",
        " \n",
        "# Google colab bibliotekų įkėlimas, skirtos duomenų nuskaitymui, apdorojimui, išsaugojimui \n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "from google.colab import drive\n",
        "import sys\n",
        "import platform\n",
        "import seaborn as sn\n",
        " \n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "sys.path.append('/content/gdrive/My Drive/Bakalauras/Data/ambers')\n",
        "print(sys.version)\n",
        "platform.python_version()\n",
        "sys.version_info\n",
        "\n",
        "\n",
        "\n",
        "#           Globalūs kintmieji \n",
        "\n",
        "# 8 - sienų nurodymas, grandinės kodui.\n",
        "kodoSarasas = [5,6,7,4,8,0,3,2,1]\n",
        "\n",
        "# Pasirinkimas atspausdinti tarpinius rezultatų kintamuosius ir rezultatus\n",
        "arSektiIrasus = 0\n",
        "#         Nuotraukų apdorojimų metodai\n",
        "\n",
        "\n",
        "def kombinacijos(s):\n",
        "  if len(s) == 2:\n",
        "    yield [s]\n",
        "  for x in s[1:]:\n",
        "    pirmaDalis = ''.join((s[0], x))\n",
        "    likusiDalis = ''.join(c for c in s if c not in pirmaDalis)\n",
        "    for kombinacija in kombinacijos(likusiDalis):\n",
        "      yield [pirmaDalis] + kombinacija\n",
        "\n",
        "def sumazintiNuotraukosMasteli(nuotrauka, plotis=None, aukstis=None, inter=cv2.INTER_AREA):\n",
        "    dimensija = None\n",
        "    (aukst, plot) = nuotrauka.shape[:2]\n",
        " \n",
        "    if plotis is None and aukstis is None:\n",
        "        return nuotrauka\n",
        "    if plotis is None:\n",
        "        r = aukstis / float(aukst)\n",
        "        dimensija = (int(plot * r), aukstis)\n",
        "    else:\n",
        "        r = plotis / float(plot)\n",
        "        dimensija = (plotis, int(aukst * r))\n",
        " \n",
        "    return cv2.resize(nuotrauka, dimensija, interpolation=inter)\n",
        "\n",
        "\n",
        "def maziausiaDezute(a): # nukerpame nereikalingas gintaro dalis.\n",
        "            r = a.any(1)\n",
        "            if r.any():\n",
        "                m,n = a.shape\n",
        "                c = a.any(0)\n",
        "                rezultatas = a[r.argmax():m-r[::-1].argmax(), c.argmax():n-c[::-1].argmax()]\n",
        "            else:\n",
        "                rezultatas = np.empty((0,0),dtype=bool)\n",
        "            return rezultatas\n",
        "\n",
        "def taskavimas(a,x,y): # \n",
        "    r = a\n",
        "    r[x][y] = 0;\n",
        "    c,v = r.shape\n",
        "    if c > x+1:\n",
        "      r[x+1][y] = 255\n",
        "    if c > x-1 and x-1 >= 0:\n",
        "      r[x-1][y] = 255\n",
        "    if c > x-2 and x-2 >= 0:\n",
        "      r[x-1][y] = 0\n",
        "    return r\n",
        "\n",
        "\n",
        "def vertikalusApvertimas(nuotrauka):\n",
        "  \"\"\"\n",
        "  Pilkojo vaizdo atvaizdo pasukimo metodas, atsižvelgiant į jo pagrindinę ašį. \n",
        "  \"\"\"\n",
        "  \n",
        "  # Gauname mus dominančias objekto koordinates\n",
        "  X = np.array(np.where(nuotrauka > 0)).T\n",
        "  if len(X) > 0:\n",
        "\n",
        "    # PCA apskaiciavimas kampo pagal pagrindines asis\n",
        "    rezultatasPCA = PCA(n_components=2).fit(X)\n",
        "    kampas = np.arctan2(*rezultatasPCA.components_[0])\n",
        "    \n",
        "    # Apsukame nuotrauką pagal apskaičiuotą kampą.\n",
        "    pasuktaNuotrauka = rotate(nuotrauka,kampas/math.pi*180-90)\n",
        "\n",
        "    pasuktaNuotrauka = nezinomuReiksmiuPasalinimas(pasuktaNuotrauka)\n",
        "    return pasuktaNuotrauka\n",
        "  else:\n",
        "    return nuotrauka\n",
        "\n",
        "\n",
        "def perziuretiDvejetaineNuotrauka(aplankalas=\"/content/gdrive/My Drive/Bakalauras/Data/image_from_binary\"):\n",
        "  \n",
        "  sarasas = os.listdir(aplankalas)\n",
        "  sarasas = sorted(sarasas, key=lambda a: int(a.split(\".\")[0].split(\"-\")[0]),reverse=False )\n",
        "  \n",
        "  for failoPavadinimas in sarasas:\n",
        "      failoPatikra1 = pathlib.Path(os.path.join(aplankalas,failoPavadinimas))\n",
        "      \n",
        "      if failoPatikra1.exists():\n",
        "        print(failoPavadinimas)\n",
        "\n",
        "        nuotrauka = cv2.imread(aplankalas+ \"/\" + failoPavadinimas, 2) \n",
        "        nuotrauka = cv2.resize(nuotrauka, (224, 224))\n",
        "            \n",
        "        nuotrauka[nuotrauka < 200] = 0\n",
        "        nuotrauka[nuotrauka > 200] = 255\n",
        "\n",
        "        plt.imshow(nuotrauka, interpolation='nearest')\n",
        "        plt.show()\n",
        "        \n",
        "  print(\"done\")\n",
        "\n",
        "def nuotraukos_grotelelese(nuotraukos, eiles, kolonos):\n",
        "  assert len(nuotraukos) == eiles*kolonos\n",
        "\n",
        "  plot, aukst = nuotraukos[0].size\n",
        "  groteles = Image.new('RGB', size=(kolonos*plot, eiles*aukst))\n",
        "  groteles_plot, groteles_aukstis = groteles.size\n",
        "  \n",
        "  for i, nuotrauka in enumerate(nuotraukos):\n",
        "      groteles.paste(nuotrauka, box=(i%kolonos*plot, i//kolonos*aukst))\n",
        "  return groteles\n",
        "\n",
        "\n",
        "# Dvejetainės nuotraukos savybių išgavimo metodai \n",
        "\n",
        "def centroido_apskaiciavimas(nuotrauka):\n",
        "\n",
        "  # Konvertuojame nuotrauka į pilko formato nuotrauką\n",
        "  spalva = 255\n",
        "  \n",
        "  # Konvertuoti pilkos formos nuotrauka i binarine\n",
        "  # isrankioti nuotraukos momentus\n",
        "  Momentai = cv2.moments(nuotrauka)\n",
        "\n",
        "  # apskaičiuojame x ir y centro koordinates\n",
        "  koordinate1, koordinate2 = ndimage.measurements.center_of_mass(nuotrauka)\n",
        "\n",
        "  koordinateX = int(koordinate1)#int(M[\"m10\"] / M[\"m00\"])\n",
        "  koordinateY = int(koordinate2)#int(M[\"m01\"] / M[\"m00\"])\n",
        "\n",
        "  # ikelti teksta ir ji pazymeti\n",
        "  cv2.circle(nuotrauka, (koordinateX, koordinateY), 5, (spalva, spalva, spalva), -1)\n",
        "  cv2.putText(nuotrauka, \"centroid\", (koordinateX - 25, koordinateY - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (spalva, spalva, spalva), 2)\n",
        "\n",
        "  # rodyti nuotrauka\n",
        "  plt.imshow(nuotrauka, interpolation='nearest')\n",
        "  plt.show()\n",
        "\n",
        "  koordinateX = int(Momentai[\"m10\"] / Momentai[\"m00\"])\n",
        "  koordinateY = int(Momentai[\"m01\"] / Momentai[\"m00\"])\n",
        "\n",
        "  # ikelti ir pazymeti teksta\n",
        "  cv2.circle(nuotrauka, (koordinateX, koordinateY), 5, (spalva, spalva, spalva), -1)\n",
        "  cv2.putText(nuotrauka, \"centroid\", (koordinateX - 25, koordinateY - 25),cv2.FONT_HERSHEY_SIMPLEX, 0.5, (spalva, spalva, spalva), 2)\n",
        "\n",
        "  plt.imshow(nuotrauka, interpolation='nearest')\n",
        "  plt.show()\n",
        "\n",
        "def masesCentras(nuotrauka):\n",
        "  momentasX = 0\n",
        "  momentasY = 0\n",
        "  skaitliukas = 0\n",
        "\n",
        "  for i in range(nuotrauka.shape[0]):\n",
        "      for j in range(nuotrauka.shape[1]):\n",
        "          if nuotrauka[i, j] >= 255:\n",
        "              momentasX = momentasX + j\n",
        "              momentasY = momentasY + i\n",
        "              skaitliukas = skaitliukas + 1\n",
        "\n",
        "  if skaitliukas > 0:\n",
        "    centrasX = int(momentasX / skaitliukas)\n",
        "    centrasY = int(momentasY / skaitliukas)\n",
        "    return centrasX, centrasY\n",
        "  else:\n",
        "    return np.nan, np.nan\n",
        "\n",
        "def uzkrautiNuotraukas(vietos,aplankalas):\n",
        "    laikinas = []\n",
        "    for vieta in vietos:\n",
        "        vietosPatikrinimas = pathlib.Path(os.path.join(aplankalas,vieta))\n",
        "        laikinas.append(imread(vietosPatikrinimas))\n",
        "    return laikinas\n",
        "\n",
        "def kombinacijosSeka(s, centroidai, pasirinkimas, pasirinkimas_c = 1):\n",
        "  sarasas = []\n",
        "  likusiDalis = ''.join(str(c) for c in range(len(s)))\n",
        "  sasasoSuma = []\n",
        "  centroiduSarasas = []\n",
        "\n",
        "  kombinacijosR = list(kombinacijos(likusiDalis))\n",
        "  for kombA in kombinacijosR:\n",
        "\n",
        "    mazasSarasas = []\n",
        "    mazasCentroiduSarasas = []\n",
        "    sarasasS = 0\n",
        "\n",
        "    for kombB in kombA:\n",
        "\n",
        "      didziausiasSarasas = []\n",
        "      laikinasCentroiduSarasas = []\n",
        "\n",
        "      for kombC in kombB:\n",
        "\n",
        "        didziausiasSarasas.append(s[int(c)])\n",
        "\n",
        "        if len(centroidai) > 0:\n",
        "          laikinasCentroiduSarasas.append(centroidai[int(c)])\n",
        "\n",
        "      sarasasS += (abs(np.diff(didziausiasSarasas)))\n",
        "      mazasSarasas.append(didziausiasSarasas)\n",
        "      mazasCentroiduSarasas.append(laikinasCentroiduSarasas)\n",
        "\n",
        "    sasasoSuma.append(float(sarasasS))\n",
        "    sarasas.append(mazasSarasas)\n",
        "    centroiduSarasas.append(mazasCentroiduSarasas)\n",
        "\n",
        "  # gauname surusiuoto array pointerius, nerusiuojant pacio array\n",
        "  surusuiuotosTaskuReiksmes = [i[0] for i in sorted(enumerate(sasasoSuma), key=lambda i: i[1])][0] \n",
        "  \n",
        "  rezultatas = []\n",
        "  for kombA in sarasas[surusuiuotosTaskuReiksmes]:\n",
        "    if pasirinkimas == 0:      \n",
        "      rezultatas.append(max(kombA))\n",
        "    elif pasirinkimas == 1:\n",
        "        rezultatas.append(sum(kombA)/len(kombA))\n",
        "  \n",
        "  if len(centroidai) > 0:\n",
        "    centroiduRezultatai = []\n",
        "\n",
        "    for kombA in centroiduSarasas[surusuiuotosTaskuReiksmes]:\n",
        "\n",
        "      if pasirinkimas_c == 0:      \n",
        "        centroiduRezultatai.append(max(kombA))\n",
        "      elif pasirinkimas_c == 1:\n",
        "          centroiduRezultatai.append(sum(kombA)/len(kombA))\n",
        "\n",
        "    # print(details)  \n",
        "    return rezultatas, sarasas[surusuiuotosTaskuReiksmes], centroiduRezultatai\n",
        "  else:\n",
        "    return rezultatas, sarasas[surusuiuotosTaskuReiksmes]\n",
        "\n",
        "\n",
        "def nezinomuReiksmiuPasalinimas(nuotr):\n",
        "  if nuotr is not None:\n",
        "    nuotr[nuotr < 200] = 0\n",
        "    nuotr[nuotr > 200] = 255\n",
        "  return nuotr\n",
        "\n",
        "def kaimynuKiekis(nuotraukuMatrica, i, j, W, H): \n",
        "    skaitliukas = 0; \n",
        "    if (i > 0 and nuotraukuMatrica[i - 1][j]): \n",
        "        skaitliukas+= 1\n",
        "    if (j > 0 and nuotraukuMatrica[i][j - 1]): \n",
        "        skaitliukas+= 1\n",
        "    if (i < W-1 and nuotraukuMatrica[i + 1][j]): \n",
        "        skaitliukas+= 1\n",
        "    if (j < H-1 and nuotraukuMatrica[i][j + 1]): \n",
        "        skaitliukas+= 1\n",
        "    return skaitliukas\n",
        "\n",
        "# graziname perimetro suma \n",
        "def rastiPerimetra(matavimai,R,C): \n",
        "    perimetras = 0; \n",
        "    koordinates = []\n",
        "    for i in range(0, R): \n",
        "        for j in range(0, C): \n",
        "            if (matavimai[i][j]): \n",
        "                Per  = kaimynuKiekis(matavimai, i, j,R,C)\n",
        "                perimetras += 4 - Per\n",
        "                if 4 - Per > 0:\n",
        "                  koordinates.append([i,j])\n",
        "\n",
        "    return perimetras, koordinates; \n",
        "\n",
        "def gintaroPerimetroAtvaizdavimas(a):\n",
        "  x1 = (a[:,1:] != a[:,:-1])[1:,:] \n",
        "  x2 = (a[1:,:] != a[:-1,:])[:,1:] \n",
        "  y1 = x1.astype(int)\n",
        "  y2 = x2.astype(int)\n",
        "  Rxy = y1+y2\n",
        "  return Rxy\n",
        "\n",
        "def gintaroPerimetroPristatymasViesai(matavimai,W,H):\n",
        "  koordinates = []\n",
        "  perimetras = 0;\n",
        "  for i in range(0, W): \n",
        "      for j in range(0, H): \n",
        "          if (matavimai[i][j]): \n",
        "              skaitliukas = 0; \n",
        "              if (i > 0 and matavimai[i - 1][j]): \n",
        "                  skaitliukas+= 1\n",
        "              if (j > 0 and matavimai[i][j - 1]): \n",
        "                  skaitliukas+= 1\n",
        "              if (i < W-1 and matavimai[i + 1][j]): \n",
        "                  skaitliukas+= 1\n",
        "              if (j < H-1 and matavimai[i][j + 1]): \n",
        "                  skaitliukas+= 1\n",
        "              Per  = 4 - count\n",
        "              perimetras += Per\n",
        "              if Per > 0:\n",
        "                koordinates.append([i,j])\n",
        "  return koordinates\n",
        "\n",
        "def xyApgaubtasPlotas(xyFailas):\n",
        "\tplotas = spatial.ConvexHull(xyFailas, qhull_options=\"Qt\")\n",
        "\tplotoIndeksai = plotas.vertices\n",
        "\treturn plotoIndeksai\n",
        "\n",
        "\n",
        "def apgaubtasPerimetas(a):\n",
        "  '''\n",
        "  # kampų radimas ir convex perimetras\n",
        "  ''' \n",
        "  a = np.array(a)\n",
        "  \n",
        "  plotoIndeksai = xyApgaubtasPlotas(a)\n",
        "  plotoIndeksaiXY = []\n",
        "\n",
        "  for i in range(len(plotoIndeksai)):\n",
        "\n",
        "    index = plotoIndeksai[i]\n",
        "    value_y = a[index, 0].astype('float32')\n",
        "    value_x = a[index, 1].astype('float32')\n",
        "    plotoIndeksaiXY.append([value_y, value_x])\n",
        "  \n",
        "  plotoIndeksaiXY = np.array(plotoIndeksaiXY)\n",
        "  atstumuSarasas = (plotoIndeksaiXY[:-1,0]-plotoIndeksaiXY[1:,0])**2 + (plotoIndeksaiXY[:-1,1]-plotoIndeksaiXY[1:,1])**2\n",
        "\n",
        "  abgaubtasPerimetras  = np.sum(np.sqrt(atstumuSarasas)) \n",
        "\n",
        "  return plotoIndeksaiXY, len(plotoIndeksai),  abgaubtasPerimetras\n",
        "\n",
        "\n",
        "def atstumas(p,q):\n",
        "  return math.sqrt(sum((px - qx) ** 2.0 for px, qx in zip(p, q)))\n",
        "\n",
        "def rodytiGintaroAsis(X,a1,a2,c1, c2, w_bounds,h_bounds ):\n",
        "  at = np.transpose([a1,a2])\n",
        "  plt.plot(X[0,:], X[1,:], 'k.')\n",
        "  plt.plot(at[0],at[1], '-ok')\n",
        "  plt.axis('equal')\n",
        "  # plt.gca().invert_yaxis()\n",
        "\n",
        "def pagindineAsis(am,X,c1, c2, w_bounds,h_bounds ):\n",
        "  Xt = am #np.transpose(X)\n",
        "  atstumai = distance.cdist(Xt, Xt, 'euclidean')\n",
        "\n",
        "  # Randame didžiausią reikšmę iš 2D masyvo pažymėdami jį į indeksą.\n",
        "  rezultatas = np.where(atstumai == np.amax(atstumai))\n",
        "\n",
        "  koordinaciuSarasas = list(zip(rezultatas[0], rezultatas[1]))\n",
        "  koord = koordinaciuSarasas[0]\n",
        "\n",
        "  a1 = list(Xt[koord[0]])\n",
        "  a2 = list(Xt[koord[1]])\n",
        "  xy_atstumas = atstumas(Xt[koord[0]],Xt[koord[1]])\n",
        "  \n",
        "  if arSektiIrasus:\n",
        "    rodytiGintaroAsis(X,a1,a2,c1, c2, w_bounds,h_bounds )\n",
        "\n",
        "  return xy_atstumas, [a1,a2]\n",
        "  \n",
        "def pagrindinesAsiesKampas(aKoordinates):\n",
        "  t1 = (aKoordinates[1][1]-aKoordinates[0][1])\n",
        "  t2 = (aKoordinates[1][0]-aKoordinates[0][0])\n",
        "\n",
        "  if t2 != 0:\n",
        "    tn = t1/t2\n",
        "    atanLaipsniai = math.degrees(math.atan(tn))\n",
        "    return atanLaipsniai\n",
        "  else: \n",
        "    return 0\n",
        "    \n",
        "def apgaubtoHullPlotas(pts):\n",
        "    pts\n",
        "    eilutes = np.hstack([pts,np.roll(pts,-1,axis=0)])\n",
        "    plotas = 0.5*abs(sum(x1*y2-x2*y1 for x1,y1,x2,y2 in eilutes))\n",
        "    return plotas\n",
        "\n",
        "def centro_WH(x,y,a):\n",
        "  xIlgis=0\n",
        "  y_ilgis=0\n",
        "\n",
        "  for i in range(a.shape[0]):\n",
        "    if a[i][int(y)] > 0:\n",
        "      y_ilgis += 1\n",
        "\n",
        "  for i in range(a.shape[1]):\n",
        "    if a[int(x)][i] > 0:\n",
        "      xIlgis += 1\n",
        "  return xIlgis, y_ilgis\n",
        "  \n",
        "def gintaroPlotas(a):\n",
        "  pikseliai = cv2.countNonZero(a) # suskaiciuojame kiek yra uzpildyto nuotrauka pixeliu\n",
        "  nuotraukosPlotas = a.shape[0] * a.shape[1] # nuotraukos plotis ir ilgis \n",
        "  plotoSantykis = (pikseliai / nuotraukosPlotas) * 100 # plotis gintaro nuotraukoje;\n",
        "  \n",
        "  # Atspausdiname paprastus rezultatus patikrai\n",
        "  if arSektiIrasus:\n",
        "    print('pikseliai', pikseliai)\n",
        "    print('Image plotas', nuotraukosPlotas, a.shape[0], a.shape[1])\n",
        "    print('plotas ratio', plotoSantykis)\n",
        "\n",
        "  return pikseliai, plotoSantykis\n",
        "\n",
        "\n",
        "def atspausdintiMatrica(a):\n",
        "  print('\\n'.join([''.join(['{:4}'.format(item) for item in row])  for row in a]))\n",
        "\n",
        "\n",
        "def gintaroMazDidzAsys(perimetroKoordinates):\n",
        "  perimetrasC = np.array(perimetroKoordinates)\n",
        "  perimetrasCTransponuotas = np.transpose(perimetrasC)\n",
        "\n",
        "  return perimetrasC, perimetrasCTransponuotas\n",
        "\n",
        "\n",
        "def rastiKompaktiskuma(A, P): \n",
        "  # isoperimetric quotient on a plane: https://en.wikipedia.org/wiki/Isoperimetric_inequality\n",
        "  # http://www.markedbyteachers.kombinacija/gcse/maths/to-investigate-the-isoperimetric-quotient-iq-of-plane-shapes-using-the-calculation-shown-below.html\n",
        "\n",
        "  Q = 0;\n",
        "\n",
        "  if P > 0:\n",
        "    Q = ( 4 * math.pi * A) / (P**2)\n",
        "  return Q\n",
        "  \n",
        "def koordinatesI2Dsarasa(P,plot,aukst):\n",
        "\n",
        "  gintaroRibuMatrica = np.full((aukst + 1, plot + 1), False, dtype=bool)\n",
        "\n",
        "  for k in P:\n",
        "    x = k[0]\n",
        "    y = k[1]\n",
        "    gintaroRibuMatrica[y,x] = True\n",
        "\n",
        "  # atspausdintiMatrica(gintaroRibuMatrica)\n",
        "\n",
        "  return gintaroRibuMatrica\n",
        "\n",
        "def rusiuotiXYPagalLaikrodzioRod(x, y): \n",
        "\n",
        "  Xnull = np.mean(x)\n",
        "  Ynull = np.mean(y)\n",
        "\n",
        "  r = np.sqrt((x-Xnull)**2 + (y-Ynull)**2)\n",
        "\n",
        "  kampai = np.where((y-Ynull) > 0, np.arccos((x-Xnull)/r), 2*np.pi-np.arccos((x-Xnull)/r))\n",
        "\n",
        "  mk = np.argsort(kampai)\n",
        "\n",
        "  surusiuotasX = x[mk]\n",
        "  surusiuotasY = y[mk]\n",
        "\n",
        "  return surusiuotasX, surusiuotasY\n",
        "\n",
        "\n",
        "def grandinelesKodas(x1, y1, x2, y2):   \n",
        "  grandinelesRaktas = 3 * (x2 - x1 ) + (y2 - y1) + 4\n",
        "  \n",
        "  if grandinelesRaktas >= len(kodoSarasas) or  0 >= grandinelesRaktas :\n",
        "    return 8\n",
        "  else :\n",
        "    return kodoSarasas[grandinelesRaktas]\n",
        "  \n",
        "def grandinelesSarasas(sarasasXY): \n",
        "\n",
        "  grandinelesSarasas = [] \n",
        "  \n",
        "  for i in range(len(sarasasXY) - 1): \n",
        "      a = sarasasXY[i] \n",
        "      b = sarasasXY[i + 1] \n",
        "      grandinelesSarasas.append(grandinelesKodas(a[0], a[1], b[0], b[1])) \n",
        "  \n",
        "  return grandinelesSarasas \n",
        "\n",
        "def ismatuotiConvexity(a,b):\n",
        "  return a/b\n",
        "\n",
        "\n",
        "def dydzioFormatas(b): # Išvestis skirta atspausdinti sunaudojamą ram kiekį.\n",
        "\n",
        "  if b < 1000:\n",
        "            return '%i' % b + 'B'\n",
        "\n",
        "  elif 1000 <= b < 1000000:\n",
        "      return '%.1f' % float(b/1000) + 'KB'\n",
        "\n",
        "  elif 1000000 <= b < 1000000000:\n",
        "      return '%.1f' % float(b/1000000) + 'MB'\n",
        "\n",
        "  elif 1000000000 <= b < 1000000000000:\n",
        "      return '%.1f' % float(b/1000000000) + 'GB'\n",
        "\n",
        "  elif 1000000000000 <= b:\n",
        "      return '%.1f' % float(b/1000000000000) + 'TB'\n",
        "\n",
        "\n",
        "\n",
        "def nuskaitytiOriginaliaNuotrauka_KonvertuotiIOriginaliaApkarpyta(aplankalas , dvejetainiuNuotraukuVieta ):\n",
        "  # Kodo dalis skirta nuskaityti nuotraukas, o tas nuotraukas sumazinti rezoliucija ir issaugoti binary formatu nuotraukoje, jeigu ta nuotrauka\n",
        "  # egzistuoja jos darkartą nesaugos į binary nuotrauk1/formą kad sutaupytume laiko ir vietos size buvo sumažintas iki 360 pločio su Automatiniu aspect ratio\n",
        "\n",
        "  testi = True\n",
        "  try:\n",
        "    sarasas = os.listdir(aplankalas)\n",
        "  except FileNotFoundError:\n",
        "    print(\"!! Folder was not found !!\")\n",
        "    testi = False\n",
        "  if testi:\n",
        "    sarasas = sorted( sarasas, key=lambda a: int(a.split(\".\")[0].split(\"-\")[0]),reverse=False )\n",
        "    for failoPavadinimas in sarasas:\n",
        "        \n",
        "        failoPatikra1 = pathlib.Path(os.path.join(aplankalas,failoPavadinimas))\n",
        "        if failoPatikra1.exists():\n",
        "          dvejetainioFailoPavadinimas = failoPavadinimas #.split(\".\")[0]  + \".bin\"\n",
        "          if not os.path.isdir(os.path.abspath(dvejetainiuNuotraukuVieta)):\n",
        "            if not os.path.exists(dvejetainiuNuotraukuVieta):\n",
        "              os.mkdir(dvejetainiuNuotraukuVieta)\n",
        "              print(\"Creating new directory: \", dvejetainiuNuotraukuVieta)\n",
        "\n",
        "\n",
        "          failoPatikra2 = pathlib.Path(os.path.join(dvejetainiuNuotraukuVieta, dvejetainioFailoPavadinimas) )\n",
        "          print(failoPatikra2)\n",
        "          \n",
        "          if failoPatikra2.exists() != True :\n",
        "            nuotrauka = cv2.imread(os.path.join(aplankalas,failoPavadinimas),0) \n",
        "\n",
        "            # patikrinimas jei None - tai reiskia blogai nusiskaitė, jei yra duomenys tada reiskiasi yra nuskaitytas\n",
        "            if nuotrauka is not None:  \n",
        "              ret, bw_nuotrauka = cv2.threshold(nuotrauka, 127, 255, cv2.THRESH_BINARY) \n",
        "\n",
        "              # Konvertuojame į binarinę formą \n",
        "              # # binarines formos array kuris bus panaudojamas duomenims ir ju analizei\n",
        "              bw_nuotrauka_rs = sumazintiNuotraukosMasteli(bw_nuotrauka, plotis=360) \n",
        "              # Dydzio pakeitimas H: 480 W: 360          \n",
        "              # dydi keiciama pagal ploti islaikant vienoda aspect ratio; \n",
        "\n",
        "              suliejimas = cv2.GaussianBlur(bw_nuotrauka_rs, (3,3), 0)\n",
        "              thresh = cv2.threshold(suliejimas, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
        "\n",
        "              # Morph uzdarrymas ir invertavimas nuotraukos\n",
        "              kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
        "              close = 255 - cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "              des = cv2.bitwise_not(close)\n",
        "\n",
        "              contour,hier = cv2.findContours(des,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "              for skaitliukas in contour:\n",
        "                  cv2.drawContours(des,[skaitliukas],0,255,-1)\n",
        "\n",
        "              bw_nuotrauka_rs = des\n",
        "              kernel = np.ones((5,5),np.uint8)\n",
        "              erosion = cv2.erode(bw_nuotrauka_rs,kernel,iterations = 1)\n",
        "\n",
        "              QR_final = vertikalusApvertimas(erosion)\n",
        "              QR_final = maziausiaDezute(QR_final)\n",
        "              \n",
        "              \n",
        "              c1, c2 = ndimage.measurements.center_of_mass(QR_final)\n",
        "              if not math.isnan(c1) and not math.isnan(c2):\n",
        "              \n",
        "                PILimage = Img.fromarray(QR_final)\n",
        "                PILimage.save(os.path.join(dvejetainiuNuotraukuVieta,failoPavadinimas))\n",
        "\n",
        "              else:\n",
        "                print(\"Failed to save nuotrauka:\" + failoPavadinimas + \"\\n try to make new object nuotrauka, with better background\")\n",
        "    \n",
        "            else:\n",
        "              print(\"Image reading failed\")\n",
        "\n",
        "\n",
        "def CDF(xt,yt,gx,gy):\n",
        "  return math.sqrt((xt-gx)**2 + (yt-gy)**2)\n",
        "\n",
        "\n",
        "def CDFSarasas(arr, gx,gy,perimetrasCTransponuotas, m = 64):\n",
        "  n = len(arr) -1\n",
        "  i = 0.0 \n",
        "  aukst = float(n) / float(m) \n",
        "  return_arr = []\n",
        "  skaitliukas = 0\n",
        "\n",
        "  \n",
        "  if arSektiIrasus > 0:\n",
        "    plt.plot(perimetrasCTransponuotas[0,:], perimetrasCTransponuotas[1,:], 'k.')\n",
        "    \n",
        "  while i <= n:\n",
        "    if skaitliukas < m:\n",
        "      i += aukst\n",
        "      skaitliukas += 1\n",
        "      ii = math.floor(i)\n",
        "      return_arr.append(CDF(arr[ii][0],arr[ii][1],gx,gy))\n",
        "      if arSektiIrasus > 0:\n",
        "        plt.plot([arr[ii][0],gx],[arr[ii][1],gy], '-og');\n",
        "    else: \n",
        "      break\n",
        "\n",
        "  if arSektiIrasus > 0:\n",
        "    plt.axis('equal')\n",
        "    plt.xlabel(\"X\")\n",
        "    plt.ylabel(\"Y\")\n",
        "    plt.show()\n",
        "    plt.plot(return_arr)\n",
        "\n",
        "    plt.title(\"CDF - Centroidų atstumų funkcijos atstumai\")\n",
        "    plt.xlabel(\"Iteracija\")\n",
        "    plt.ylabel(\"Atstumas\")\n",
        "    plt.show()\n",
        "  \n",
        "  return return_arr\n",
        "\n",
        "\n",
        "def imageDimentions(nuotr, path, process):\n",
        "  # Įvairios formų analizės ir matavimai \n",
        "  # http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf\n",
        "\n",
        "  # Mases centras kuriuo apskaiciuojama zymiai greiciau negu   # print(centerofmass(nuotrauka))\n",
        "  c1, c2 = ndimage.measurements.center_of_mass(nuotr) \n",
        "\n",
        "  # apskaičiavimas nuo centro koks yra aukstis y ir ilgis x\n",
        "  xIlgis,y_ilgis = centro_WH(c1,c2,nuotr)\n",
        "\n",
        "  # Gintaro ploto nuotraukoje apskaiciavimas :\n",
        "  area_pixels, plotoSantykis = gintaroPlotas(nuotr)\n",
        "\n",
        "  # gintaro aukštis ir plotis (aukstis and plotis). naudojantis cv2 irankiu\n",
        "  x,y,w_bounds,h_bounds = cv2.boundingRect(nuotr) # Straight Bounding Rectangle\n",
        "\n",
        "  # GINTARO objekto perimetras (object perimetras)\n",
        "  perimetras, perimetroKoordinates = rastiPerimetra(nuotr, nuotr.shape[0], nuotr.shape[1]) # tikslesnis budas\n",
        "  \n",
        "  # gintaro diametras, tolimiausia pagrindine gintaro asis # bandymas apskaiciuoti 45laipsniu skersmens ilgi; DIAMETRAS\n",
        "  perimetrasC,perimetrasCTransponuotas = gintaroMazDidzAsys(perimetroKoordinates)\n",
        "\n",
        "  # 45 degree koordinates\n",
        "  lenOf45Deg = angleBetweenTwoPoints(perimetrasC,c1,c2)\n",
        "\n",
        "  # gintaro diametras, tolimiausia pagrindine gintaro asis\n",
        "  # major_ax_d, major_ax  = major_axis(perimetrasC,perimetrasCTransponuotas)\n",
        "  major_ax_d, major_ax  = pagindineAsis(perimetrasC,perimetrasCTransponuotas,c1, c2, w_bounds,h_bounds  )\n",
        "\n",
        "  # major axis kampas degrees:\n",
        "  major_ax_deg          = pagrindinesAsiesKampas(major_ax)\n",
        "\n",
        "  # Kampų radimas, convex shape kapų kiekis, convex perimetras\n",
        "  temp = np.array(perimetroKoordinates)\n",
        "  if sum(temp[:,1]) >0 and sum(temp[:,0]) >= 0:\n",
        "    convex_xy, convex_angles, convex_perimeter   = apgaubtasPerimetas(perimetroKoordinates) # maziausias apgaubtas plotas kuris uzdaro visa forma\n",
        "    convexHull_area_size = apgaubtoHullPlotas(convex_xy)\n",
        "    if arSektiIrasus:\n",
        "      a1 = list(convex_xy[:,0])\n",
        "      a2 = list(convex_xy[:,1])\n",
        "      at = np.transpose([a1,a2])\n",
        "      plt.plot(a1,a2, '-or');\n",
        "      plt.axis('equal')\n",
        "      plt.xticks(rotation=-90)\n",
        "      plt.yticks(rotation=-90)\n",
        "      plt.xlabel(\"Y\")\n",
        "      plt.ylabel(\"X\")\n",
        "\n",
        "      plt.show()\n",
        "  else:\n",
        "    convexHull_area_size = 0\n",
        "    convex_xy = []\n",
        "    convex_angles = 0\n",
        "    convex_perimeter = 0\n",
        "\n",
        "  #  isoperimetric quotient: Kompaktiškumo radimas, kai apvaliausias objektas yra kompaktišiausias \n",
        "  Q_compactness                   = rastiKompaktiskuma(area_pixels,perimetras)\n",
        "\n",
        "  # Circularity or Roundness naudojantic covnex perimetru arba perimetru\n",
        "  Q_roundness = rastiKompaktiskuma(area_pixels,convex_perimeter)\n",
        "\n",
        "  \n",
        "  # Boundary Descriptors arba Chain code arba Kraštinių nusakymas\n",
        "  perimetrasC[:,0],perimetrasC[:,1] = rusiuotiXYPagalLaikrodzioRod(perimetrasC[:,0],perimetrasC[:,1])\n",
        "\n",
        "  amber_chainLst = (grandinelesSarasas(perimetrasC))\n",
        "  amber_chainLst = ''.join(str(e) for e in amber_chainLst)\n",
        "\n",
        "  # Convexity\n",
        "  convexity_q = ismatuotiConvexity(convex_perimeter, len(perimetroKoordinates))\n",
        "\n",
        "  # CDF Centroid distance function\n",
        "  CDF_array = CDFSarasas(perimetrasC,c1,c2,perimetrasCTransponuotas)\n",
        "\n",
        "  # print(perimetrasC.shape)\n",
        "  if arSektiIrasus:\n",
        "    print(\"center of mass:\",c1,c2)\n",
        "    print(\"Image shape\", nuotr.shape)\n",
        "    print(\"PERIMETRAS\",perimetras, \"PERIMETRO KOORDINATES ILGIS\", len(perimetroKoordinates))\n",
        "    print(\"Gintaro diametras:\", major_ax_d, \"    Gintaro diametro X1Y1 X2Y2:\",major_ax)\n",
        "    print(str(major_ax_deg) + \" kampas degrees\")\n",
        "    print(\"45 laipsniu kampo atstumas tarp krastiniu.\", lenOf45Deg)\n",
        "    print(\"Uždari convex array kampai\",         convex_angles)\n",
        "    print(\"Uždaro convex array perimetras \",    convex_perimeter)\n",
        "    print(\"apgaubtoHullPlotas\",                    convexHull_area_size)\n",
        "    print(\"Isoperimetric quotient - compactness\",  Q_compactness)\n",
        "    print(\"Circularity or Roundness\",           Q_roundness)\n",
        "    print(\"Amber Chain List\",                   amber_chainLst, \"/n\\nIt's lenght\", len(amber_chainLst))\n",
        "    print(\"CDF - Centroid distance function\",   CDF_array)\n",
        "\n",
        "  return xIlgis,y_ilgis, w_bounds,h_bounds,c1,c2 , perimetras, convex_angles, convex_perimeter, area_pixels, plotoSantykis,major_ax_d, major_ax, major_ax_deg , convexHull_area_size, Q_compactness, Q_roundness, amber_chainLst, CDF_array, lenOf45Deg\n",
        "\n",
        "def main_data_preperation(sarasas, aplankalas, process, pasirinkimas = 0):\n",
        "  df = pd.DataFrame(); df_main = pd.DataFrame()\n",
        "  previous = 0; lastrow_amber = -1; imageCnt = 0;\n",
        "  amber = []; centroidHist = []; perimeter_lst = []; center_distances = []; area_ratio_lst = []; pixels_inAshape = []; convexHull_area_size_list = []; convex_perimeterList = []; amber_majorAxisLength = []; amber_majorAxisLength_XY = []\n",
        "  amber_ax_deg = []; Q_compactness_lst = []; Q_roundness_lst = []; convex_allAngles = [];\n",
        "  amber_chainCode = list()\n",
        "\n",
        "  for failoPavadinimas in sarasas:\n",
        "      failoPatikra1 = pathlib.Path(os.path.join(aplankalas,failoPavadinimas))\n",
        "      \n",
        "      if failoPatikra1.exists():\n",
        "        amber_itteration = int(failoPavadinimas.split(\".\")[0].split(\"-\")[0])\n",
        "        \n",
        "        if lastrow_amber != amber_itteration:\n",
        "          del amber_chainCode[:]\n",
        "          del amber[:], centroidHist[:],perimeter_lst[:], center_distances[:], area_ratio_lst[:], pixels_inAshape[:], convexHull_area_size_list[:], convex_perimeterList[:], amber_majorAxisLength[:], amber_majorAxisLength_XY[:]\n",
        "          del amber_ax_deg[:], Q_compactness_lst[:], Q_roundness_lst[:], convex_allAngles[:];\n",
        "          imageCnt = 0 \n",
        "        \n",
        "        imageCnt+=1\n",
        "\n",
        "        if imageCnt <= 3:\n",
        "          nuotrauka = cv2.imread(aplankalas+ \"/\" + failoPavadinimas, 0)\n",
        "          if nuotrauka is not None:\n",
        "            print(\"Filename:\",failoPavadinimas)\n",
        "            nuotrauka = nezinomuReiksmiuPasalinimas(nuotrauka)\n",
        "\n",
        "            \"\"\"\n",
        "            # Nuotraukos apvertimas vertikalia - Y - ašimi\n",
        "            # nuotrauka = vertikalusApvertimas(nuotrauka)\n",
        "            # nuotrauka = cv2.bitwise_not(nuotrauka)  # nuotraukos invertavimas\n",
        "            # nuotrauka = cv2.resize(nuotrauka, (50, 50))        # pakeiciamas visu nuotrauku didis i standartini kad visu butu vienodas, reikalinga lyginimui pagal ploti gyli forma.\n",
        "            \"\"\"\n",
        "          \n",
        "            # Ivairus budai apskaiciuoti gintaro ilgi, auksti per centra ir kitus parametrus. \n",
        "            atsx,atsy,atsW,atsH, c1,c2, perimetras, convex_kampai, convex_perimetras, pikseliai, plotoSantykis, major_ax_d, major_ax_xy, major_ax_deg, convexHull_area_size, Q_compactness,Q_roundness, amber_chainLst, CDF_list, lenOf45Deg  = imageDimentions(nuotrauka,os.path.join(aplankalas,failoPavadinimas),process)\n",
        "            \n",
        "            data = { \n",
        "              'Filename': [failoPavadinimas],\n",
        "              'amber_cnt': [failoPavadinimas.split(\".\")[0].split(\"-\")[0]],\n",
        "              'amber_picture': [failoPavadinimas.split(\".\")[0].split(\"-\")[1]],\n",
        "              'Xc': [c1], \n",
        "              'Yc': [c2],\n",
        "              'plotoSantykis':[plotoSantykis],\n",
        "              'plotas': [pikseliai],\n",
        "              'plotis':[atsW],\n",
        "              'aukstis':[atsH],\n",
        "              'X_heigth':[atsx],\n",
        "              'Y_heigth':[atsy],\n",
        "              'diameter_len':[lenOf45Deg],\n",
        "              'convex_area ':[convexHull_area_size],\n",
        "              'convex_angles_cnt ':[convex_kampai],\n",
        "              'convex_perimeter':[convex_perimetras],\n",
        "              'amber_perimeter':[perimetras],\n",
        "              'major_axis_len':[major_ax_d],\n",
        "              'pagrindinesAsiesKampas':[major_ax_deg],\n",
        "              'q_compactness':[Q_compactness],\n",
        "              'q_roundness':[Q_roundness],\n",
        "              'amber_chain':[amber_chainLst],\n",
        "              'CDF':[CDF_list],\n",
        "              'major_axis_coordinates':[major_ax_xy],\n",
        "            }\n",
        "\n",
        "            #\n",
        "            df = df.append(pd.DataFrame(data) ,ignore_index=True)\n",
        "            #\n",
        "            \n",
        "            centroidHist.append(c1);\n",
        "            centroidHist.append(c2); \n",
        "            area_ratio_lst.append(plotoSantykis); \n",
        "            pixels_inAshape.append(pikseliai)\n",
        "            amber.append(atsW); amber.append(atsH); \n",
        "            center_distances.append(atsx); center_distances.append(atsy);\n",
        "            convexHull_area_size_list.append(convexHull_area_size)\n",
        "            convex_allAngles.append(convex_kampai)\n",
        "            convex_perimeterList.append(convex_perimetras)\n",
        "            perimeter_lst.append(perimetras)\n",
        "            amber_majorAxisLength.append(major_ax_d)\n",
        "            amber_majorAxisLength_XY.append(major_ax_xy)\n",
        "            amber_ax_deg.append(major_ax_deg)\n",
        "            Q_compactness_lst.append(Q_compactness)\n",
        "            Q_roundness_lst.append(Q_roundness)\n",
        "\n",
        "\n",
        "            # Kas 3-is gintaro nuotraukas sutvarkome duomenis juos prideramai suporuojant\n",
        "            if failoPavadinimas.split(\"-\")[0] == previous and imageCnt == 3: \n",
        "\n",
        "              comboxXYZ, details, centroidsXYZ = kombinacijosSeka(amber, centroidHist,0)\n",
        "              comboxXYZ_c, details_c = kombinacijosSeka(center_distances,[],0)\n",
        "\n",
        "              if pasirinkimas == 0:\n",
        "                data_main = { 'amber_cnt': [failoPavadinimas.split(\".\")[0].split(\"-\")[0]],\n",
        "                'Xh': [comboxXYZ[0]],\n",
        "                'Xw': [comboxXYZ[1]],\n",
        "                'Xz': [comboxXYZ[2]],\n",
        "                # 'Gintaro WHD': [comboxXYZ],\n",
        "                'Xc' : [centroidsXYZ[0]], \n",
        "                'Yc' : [centroidsXYZ[1]], \n",
        "                'Zc' : [centroidsXYZ[2]], \n",
        "                'diameter_len1':[(df['diameter_len'].iloc[-1])],\n",
        "                'diameter_len2':[(df['diameter_len'].iloc[-2])],\n",
        "                'diameter_len3':[(df['diameter_len'].iloc[-3])],\n",
        "                # 'Centrdoid_XYZ_coordinates' : [centroidsXYZ], \n",
        "                # 'Amber_H_W_D_fromItsCenter':[comboxXYZ_c],\n",
        "                'Xch': [comboxXYZ_c[0]],\n",
        "                'Xcw':  [comboxXYZ_c[1]],\n",
        "                'Xcz':   [comboxXYZ_c[2]],\n",
        "                # 'Gintaro Plotas':[pixels_inAshape],\n",
        "                'amber_area1':[pixels_inAshape[0]],\n",
        "                'amber_area2':[pixels_inAshape[1]],\n",
        "                'amber_area3':[pixels_inAshape[2]],\n",
        "                'amber_area_sum':[sum(pixels_inAshape)],\n",
        "                'amber_area_avg':[sum(pixels_inAshape)/len(pixels_inAshape)],\n",
        "                'area_ratio1':[area_ratio_lst[0]],\n",
        "                'area_ratio2':[area_ratio_lst[1]],\n",
        "                'area_ratio3':[area_ratio_lst[2]],\n",
        "                'area_ratio_sum':[sum(map(float,area_ratio_lst))],\n",
        "                'area_ratio_avg':[sum(area_ratio_lst)/len(area_ratio_lst)],\n",
        "                'convex_area1':[convexHull_area_size_list[0]],\n",
        "                'convex_area2':[convexHull_area_size_list[1]],\n",
        "                'convex_area3':[convexHull_area_size_list[2]],\n",
        "                'convex_area_sum':[sum(convexHull_area_size_list)],\n",
        "                'convex_area_sum':[sum(convexHull_area_size_list)/len(convexHull_area_size_list)],\n",
        "                # 'ConvexHull gintaro kampai':[convex_allAngles],\n",
        "                'convex_angles1':[convex_allAngles[0]],\n",
        "                'convex_angles2':[convex_allAngles[1]],\n",
        "                'convex_angles3':[convex_allAngles[2]],\n",
        "                'convex_angles_sum':[sum(convex_allAngles)],\n",
        "                'convex_angles_avg':[sum(convex_allAngles)/len(convex_allAngles)],\n",
        "                # 'ConvexHull Perimetras':[convex_perimeterList],\n",
        "                'convex_perimeter1':[convex_perimeterList[0]],\n",
        "                'convex_perimeter2':[convex_perimeterList[1]],\n",
        "                'convex_perimeter3':[convex_perimeterList[2]],\n",
        "                'convex_perimeter_sum':[sum(map(float,convex_perimeterList))],\n",
        "                'convex_perimeter_avg':[sum(convex_perimeterList)/len(convex_perimeterList)],\n",
        "                # 'Gintaro Perimetras':[perimeter_lst],\n",
        "                'amber_perimeter1':[perimeter_lst[0]],\n",
        "                'amber_perimeter2':[perimeter_lst[1]],\n",
        "                'amber_perimeter3':[perimeter_lst[2]],\n",
        "                'amber_perimeter_sum':[sum(perimeter_lst)],\n",
        "                'amber_perimeter_avg':[sum(perimeter_lst)/len(perimeter_lst)],\n",
        "                # 'Gintaro diametras':[amber_majorAxisLength],\n",
        "                'major_ax1':[amber_majorAxisLength[0]],\n",
        "                'major_ax2':[amber_majorAxisLength[1]],\n",
        "                'major_ax3':[amber_majorAxisLength[2]],\n",
        "                'major_ax_sum':[sum(amber_majorAxisLength)],\n",
        "                'major_ax_avg':[sum(amber_majorAxisLength)/len(amber_majorAxisLength)],\n",
        "                # 'Gintaro diametro kampas':[amber_ax_deg],\n",
        "                'major_ax_angle1':[amber_ax_deg[0]],\n",
        "                'major_ax_angle2':[amber_ax_deg[1]],\n",
        "                'major_ax_angle3':[amber_ax_deg[2]],\n",
        "                'major_ax_angle_sum':[sum(amber_ax_deg)],\n",
        "                'major_ax_angle_avg':[sum(amber_ax_deg)/len(amber_ax_deg)],\n",
        "                # 'Gintaro kompaktiskumas':[Q_compactness_lst],\n",
        "                'q_compactness1':[Q_compactness_lst[0]],\n",
        "                'q_compactness2':[Q_compactness_lst[1]],\n",
        "                'q_compactness3':[Q_compactness_lst[2]],\n",
        "                'q_compactness_sum':[sum(Q_compactness_lst)],\n",
        "                'q_compactness_avg':[sum(Q_compactness_lst)/len(Q_compactness_lst)],\n",
        "                # 'Gintaro Apvalumas':[Q_roundness_lst],\n",
        "                'q_roundness1':[Q_roundness_lst[0]],\n",
        "                'q_roundness2':[Q_roundness_lst[1]],\n",
        "                'q_roundness3':[Q_roundness_lst[2]],\n",
        "                'q_roundness_sum':[sum(Q_roundness_lst)],\n",
        "                'q_roundness_avg':[sum(Q_roundness_lst)/len(Q_roundness_lst)],\n",
        "                'chaincode1':[(df['amber_chain'].iloc[-1])],\n",
        "                'chaincode2':[(df['amber_chain'].iloc[-2])],\n",
        "                'chaincode3':[(df['amber_chain'].iloc[-3])],\n",
        "                'CDF1':[(df['CDF'].iloc[-1])],\n",
        "                'CDF2':[(df['CDF'].iloc[-2])],\n",
        "                'CDF3':[(df['CDF'].iloc[-3])],\n",
        "\n",
        "                }\n",
        "              elif pasirinkimas == 1:\n",
        "                data_main = { 'amber_cnt': [failoPavadinimas.split(\".\")[0].split(\"-\")[0]],\n",
        "                'Xh': [comboxXYZ[0]],\n",
        "                'Xw': [comboxXYZ[1]],\n",
        "                'Xz': [comboxXYZ[2]],\n",
        "                'Xc' : [centroidsXYZ[0]], \n",
        "                'Yc' : [centroidsXYZ[1]], \n",
        "                'Zc' : [centroidsXYZ[2]], \n",
        "                'amber_area_sum':[sum(pixels_inAshape)],\n",
        "                'area_ratio_sum':[sum(map(float,area_ratio_lst))],\n",
        "                'convex_area_sum':[sum(convexHull_area_size_list)],\n",
        "                'convex_angles_sum':[sum(convex_allAngles)],\n",
        "                'convex_perimeter_sum':[sum(map(float,convex_perimeterList))],\n",
        "                'amber_perimeter_sum':[sum(perimeter_lst)],\n",
        "                'major_ax_sum':[sum(amber_majorAxisLength)],\n",
        "                'Gintaro diametro kampas su ojb SUM':[sum(amber_ax_deg)],\n",
        "                'q_compactness_sum':[sum(Q_compactness_lst)],\n",
        "                'q_roundness_sum':[sum(Q_roundness_lst)],\n",
        "                'Chaincode':[amber_chainCode],\n",
        "                }\n",
        "              elif pasirinkimas == 2:\n",
        "                data_main = { 'amber_cnt': [failoPavadinimas.split(\".\")[0].split(\"-\")[0]],\n",
        "                'Xh': [comboxXYZ[0]],\n",
        "                'Xw': [comboxXYZ[1]],\n",
        "                'Xz': [comboxXYZ[2]],\n",
        "                'Xc' : [centroidsXYZ[0]], \n",
        "                'Yc' : [centroidsXYZ[1]], \n",
        "                'Zc' : [centroidsXYZ[2]], \n",
        "                'Xch': [comboxXYZ_c[0]],\n",
        "                'Xcw':  [comboxXYZ_c[1]],\n",
        "                'Xcz':   [comboxXYZ_c[2]],\n",
        "                'amber_area_avg':[sum(pixels_inAshape)/len(pixels_inAshape)],\n",
        "                'area_ratio_avg':[sum(area_ratio_lst)/len(area_ratio_lst)],\n",
        "                'ConvexHull * gintaro plotas AVG':[sum(convexHull_area_size_list)/len(convexHull_area_size_list)],\n",
        "                'convex_angles_avg':[sum(convex_allAngles)/len(convex_allAngles)],\n",
        "                'convex_perimeter_avg':[sum(convex_perimeterList)/len(convex_perimeterList)],\n",
        "                'amber_perimeter_avg':[sum(perimeter_lst)/len(perimeter_lst)],\n",
        "                'major_ax_avg':[sum(amber_majorAxisLength)/len(amber_majorAxisLength)],\n",
        "                'major_ax_angle_avg':[sum(amber_ax_deg)/len(amber_ax_deg)],\n",
        "                'q_compactness_avg':[sum(Q_compactness_lst)/len(Q_compactness_lst)],\n",
        "                'q_roundness_avg':[sum(Q_roundness_lst)/len(Q_roundness_lst)],\n",
        "                'Chaincode':[amber_chainCode],\n",
        "                }\n",
        "              elif pasirinkimas == 3:\n",
        "                data_main = { 'amber_cnt': [failoPavadinimas.split(\".\")[0].split(\"-\")[0]],\n",
        "                'Xh': [comboxXYZ[0]],\n",
        "                'Xw': [comboxXYZ[1]],\n",
        "                'Xz': [comboxXYZ[2]],\n",
        "                'Xc' : [centroidsXYZ[0]], \n",
        "                'Yc' : [centroidsXYZ[1]], \n",
        "                'Zc' : [centroidsXYZ[2]], \n",
        "                'Xch': [comboxXYZ_c[0]],\n",
        "                'Xcw':  [comboxXYZ_c[1]],\n",
        "                'Xcz':   [comboxXYZ_c[2]],\n",
        "                'amber_area1':[pixels_inAshape[0]],\n",
        "                'amber_area2':[pixels_inAshape[1]],\n",
        "                'amber_area3':[pixels_inAshape[2]],\n",
        "                'area_ratio1':[area_ratio_lst[0]],\n",
        "                'area_ratio2':[area_ratio_lst[1]],\n",
        "                'area_ratio3':[area_ratio_lst[2]],\n",
        "                'convex_area1':[convexHull_area_size_list[0]],\n",
        "                'convex_area2':[convexHull_area_size_list[1]],\n",
        "                'convex_area3':[convexHull_area_size_list[2]],\n",
        "                'convex_angles1':[convex_allAngles[0]],\n",
        "                'convex_angles2':[convex_allAngles[1]],\n",
        "                'convex_angles3':[convex_allAngles[2]],\n",
        "                'convex_perimeter1':[convex_perimeterList[0]],\n",
        "                'convex_perimeter2':[convex_perimeterList[1]],\n",
        "                'convex_perimeter3':[convex_perimeterList[2]],\n",
        "                'amber_perimeter1':[perimeter_lst[0]],\n",
        "                'amber_perimeter2':[perimeter_lst[1]],\n",
        "                'amber_perimeter3':[perimeter_lst[2]],\n",
        "                'amber_perimeter_sum':[sum(perimeter_lst)],\n",
        "                'amber_perimeter_avg':[sum(perimeter_lst)/len(perimeter_lst)],\n",
        "                'major_ax1':[amber_majorAxisLength[0]],\n",
        "                'major_ax2':[amber_majorAxisLength[1]],\n",
        "                'major_ax3':[amber_majorAxisLength[2]],\n",
        "                'major_ax_angle1':[amber_ax_deg[0]],\n",
        "                'major_ax_angle2':[amber_ax_deg[1]],\n",
        "                'major_ax_angle3':[amber_ax_deg[2]],\n",
        "                'q_compactness1':[Q_compactness_lst[0]],\n",
        "                'q_compactness2':[Q_compactness_lst[1]],\n",
        "                'q_compactness3':[Q_compactness_lst[2]],\n",
        "                'q_roundness1':[Q_roundness_lst[0]],\n",
        "                'q_roundness2':[Q_roundness_lst[1]],\n",
        "                'q_roundness3':[Q_roundness_lst[2]],\n",
        "                'Chaincode1':[(amber_chainCode[0])],\n",
        "                'Chaincode2':[(amber_chainCode[1])],\n",
        "                'Chaincode3':[(amber_chainCode[2])],\n",
        "                }\n",
        "              elif pasirinkimas == 4:\n",
        "                data_main = { 'amber_cnt': [failoPavadinimas.split(\".\")[0].split(\"-\")[0]],\n",
        "                'XhPG': [comboxXYZ],\n",
        "                'XcYZ' : [centroidsXYZ],  \n",
        "                'XchPG': [comboxXYZ_c],\n",
        "                'amber_area1':[pixels_inAshape],\n",
        "                'area_ratio1':[area_ratio_lst],\n",
        "                'convex_area1':[convexHull_area_size_list],\n",
        "                'convex_angles1':[convex_allAngles],\n",
        "                'convex_perimeter1':[convex_perimeterList],\n",
        "                'amber_perimeter1':[perimeter_lst],\n",
        "                'major_ax1':[amber_majorAxisLength],\n",
        "                'major_ax_angle1':[amber_ax_deg],\n",
        "                'q_compactness1':[Q_compactness_lst],\n",
        "                'q_roundness1':[Q_roundness_lst],\n",
        "                'Chaincode':[amber_chainCode],\n",
        "                }\n",
        "              \n",
        "              df_main = df_main.append(pd.DataFrame(data_main) ,ignore_index=True)\n",
        "            \n",
        "            previous = failoPavadinimas.split(\"-\")[0]\n",
        "            lastrow_amber = int(failoPavadinimas.split(\".\")[0].split(\"-\")[0])\n",
        "          \n",
        "            if arSektiIrasus > 0:\n",
        "              cv2_imshow(nuotrauka)\n",
        "\n",
        "  del amber_chainCode[:]\n",
        "\n",
        "  del amber[:], centroidHist[:],perimeter_lst[:], center_distances[:], area_ratio_lst[:], pixels_inAshape[:], convexHull_area_size_list[:], convex_perimeterList[:], amber_majorAxisLength[:], amber_majorAxisLength_XY[:]\n",
        "  del amber_ax_deg[:], Q_compactness_lst[:], Q_roundness_lst[:], convex_allAngles[:];\n",
        "          \n",
        "  return df, df_main\n",
        "\n",
        "def angleBetweenTwoPoints(perimetrasC,c1,c2):\n",
        "  m = 45      # https://en.wikipedia.org/wiki/Atan2 \n",
        "  m1 = 135   \n",
        "  m2 = 0     \n",
        "  m3 = 180\n",
        "  m4 = -90\n",
        "\n",
        "  last_best_diffq1 = 999;\n",
        "  last_best_diffq2 = 999;\n",
        "\n",
        "  last_best_diffq3 = 999;\n",
        "  last_best_diffq4 = 999;\n",
        "  \n",
        "  last_best_diffq5 = 999;\n",
        "  last_best_diffq6 = 999;\n",
        "  bestq1 = [0,0,0]\n",
        "  bestq2 = [0,0,0]\n",
        "  bestq3 = [0,0,0]\n",
        "  bestq4 = [0,0,0]\n",
        "  bestq5 = [0,0,0]\n",
        "\n",
        "  for krastiniuKoordinates in perimetrasC:\n",
        "    turimiRadianai = math.atan2(c2-krastiniuKoordinates[1], c1-krastiniuKoordinates[0])\n",
        "    mydegrees = math.degrees(turimiRadianai)\n",
        "    deg_ = abs((mydegrees) - m)\n",
        "    deg_1 = abs((mydegrees) + m1)\n",
        "    deg_2 = abs((mydegrees) - m2)\n",
        "    deg_3 = abs((mydegrees) - m3)\n",
        "    deg_4 = abs((mydegrees) + m4)\n",
        "    deg_5 = abs((mydegrees) - m4)\n",
        "\n",
        "    abs_degr  = (mydegrees)\n",
        "    if deg_ < last_best_diffq1 and abs_degr > 0 and abs_degr < 90:\n",
        "      last_best_diffq1 = deg_\n",
        "      bestq1=[krastiniuKoordinates[0],krastiniuKoordinates[1],mydegrees]\n",
        "\n",
        "    if deg_1 < last_best_diffq2 and abs_degr < -90 and abs_degr > -180:\n",
        "      last_best_diffq2 = deg_1\n",
        "      bestq2=[krastiniuKoordinates[0],krastiniuKoordinates[1],mydegrees]\n",
        "\n",
        "    if deg_2 < last_best_diffq3:\n",
        "      last_best_diffq3 = deg_2\n",
        "      bestq3=[krastiniuKoordinates[0],krastiniuKoordinates[1],mydegrees]\n",
        "\n",
        "    if deg_3 < last_best_diffq4:\n",
        "      last_best_diffq4 = deg_3\n",
        "\n",
        "      bestq4=[krastiniuKoordinates[0],krastiniuKoordinates[1],mydegrees]\n",
        "\n",
        "    if deg_4 < last_best_diffq5:\n",
        "      last_best_diffq5 = deg_4\n",
        "      bestq5=[krastiniuKoordinates[0],krastiniuKoordinates[1],mydegrees]\n",
        "\n",
        "    if deg_5 < last_best_diffq6:\n",
        "      last_best_diffq6 = deg_5\n",
        "      bestq6=[krastiniuKoordinates[0],krastiniuKoordinates[1],mydegrees]\n",
        "  \n",
        "  if arSektiIrasus:\n",
        "    show_amber_45degaxis(bestq1,bestq2,bestq3,bestq4,c1,c2 ,bestq5,bestq6)\n",
        "    print(\"Best 45 deg: \",bestq1, bestq2, bestq3,bestq4,\" DISTANCE BETWEEN THEM\", CDF(bestq1[0],bestq1[1],bestq2[0],bestq2[1]) )\n",
        "    print(\"Best Y: \", bestq3,bestq4,\" DISTANCE BETWEEN THEM\", CDF(bestq3[0],bestq3[1],bestq4[0],bestq4[1]) )\n",
        "    print(\"Best X: \", bestq5,bestq6,\" DISTANCE BETWEEN THEM\", CDF(bestq6[0],bestq6[1],bestq5[0],bestq5[1]) )\n",
        "  \n",
        "  ret_answ = CDF(bestq1[0],bestq1[1],bestq2[0],bestq2[1])\n",
        "\n",
        "  return ret_answ\n",
        "\n",
        "def CDF(xt,yt,gx,gy):\n",
        "  return math.sqrt((xt-gx)**2 + (yt-gy)**2)\n",
        "\n",
        "def show_amber_45degaxis(best,bestq2,bestq3,bestq4,c1,c2,bestq5,bestq6):\n",
        "\n",
        "  plt.plot((best[0],bestq2[0]),(best[1],bestq2[1]), '-og')\n",
        "\n",
        "  plt.plot((bestq3[0],bestq4[0]),(bestq3[1],bestq4[1]), '-ob')\n",
        "  \n",
        "  plt.plot((bestq5[0],bestq6[0]),(bestq5[1],bestq6[1]), '-or')\n",
        "  plt.scatter(c1,c2, marker='x',linewidth=2)\n",
        "\n",
        "def resize_aspect_fit(resize_ratio, path, save_path , extt = 'PNG'):\n",
        "    \n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "    if os.path.exists(save_path):\n",
        "      if os.path.exists(path):\n",
        "        dirs = os.listdir(path)\n",
        "        \n",
        "        for item in dirs:\n",
        "          \n",
        "          failoPatikra1 = pathlib.Path(os.path.join(save_path,item))\n",
        "          if not failoPatikra1.exists():\n",
        "            if item == '.jpg'  or item == '.jpeg' :\n",
        "              extt = 'JPEG'\n",
        "            elif item == '.png':\n",
        "              extt = 'PNG'\n",
        "\n",
        "            \n",
        "            # print(path+item)\n",
        "            if os.path.isfile((os.path.join(path,item))) and not failoPatikra1.exists():\n",
        "              # print(failoPatikra1)\n",
        "              # print(item)\n",
        "              \n",
        "              nuotrauka = Img.open((os.path.join(path,item)))\n",
        "              file_path, extension = os.path.splitext((os.path.join(save_path,item)))\n",
        "              new_image_height = int(nuotrauka.size[0] / (1/resize_ratio))\n",
        "              new_image_length = int(nuotrauka.size[1] / (1/resize_ratio))\n",
        "              nuotrauka = nuotrauka.resize((new_image_height,new_image_length), Img.ANTIALIAS)\n",
        "              nuotrauka.save(file_path  + extension, extt, quality=90)\n",
        "              print(file_path+extension)\n",
        "      else:\n",
        "        print(\"RAW nuotrauka location path doesn't exist\")\n",
        "    else:\n",
        "      print(\"Save path doesn't exist\")\n",
        "\n",
        "###################################################################\n",
        "\n",
        "csv_save_loc_group_orig = \"/content/gdrive/My Drive/Bakalauras/Data/CSV/Ambers_group.csv\"\n",
        "csv_save_loc_one_orig = \"/content/gdrive/My Drive/Bakalauras/Data/CSV/Ambers_one.csv\"\n",
        "smaller_sized_image_loc_orig = \"/content/gdrive/My Drive/Bakalauras/Data/Resized_ambers\"\n",
        "binary_image_save_location_orig = \"/content/gdrive/My Drive/Bakalauras/Data/BinaryImages\"\n",
        "raw_image_loc_orig = \"/content/gdrive/My Drive/Bakalauras/Data/149ambers\"\n",
        "sorted_image_loc_orig = \"/content/gdrive/My Drive/Bakalauras/Data/cluster/\"\n",
        "\n",
        "\n",
        "csv_save_loc_group = \"/content/gdrive/My Drive/Bakalauras/Data/test/CSV/Ambers_group.csv\"\n",
        "csv_save_loc_csv = \"/content/gdrive/My Drive/Bakalauras/Data/test/CSV/Ambers.csv\"\n",
        "csv_save_loc_one = \"/content/gdrive/My Drive/Bakalauras/Data/test/CSV/Ambers_one.csv\"\n",
        "smaller_sized_image_loc = \"/content/gdrive/My Drive/Bakalauras/Data/test/ResizedImages\"\n",
        "binary_image_save_location = \"/content/gdrive/My Drive/Bakalauras/Data/test/BinaryImages\"\n",
        "raw_image_loc = \"/content/gdrive/My Drive/Bakalauras/Data/test/RawAmberPictures\"\n",
        "sorted_image_loc = \"/content/gdrive/My Drive/Bakalauras/Data/test/cluster/\"\n",
        "\n",
        "kmean_model_loc = \"/content/gdrive/My Drive/Bakalauras/Data/K-Mean-MODEL\"\n",
        "csv_rename_loc = \"/content/gdrive/My Drive/Bakalauras/Data/test/ResizedImages\"\n",
        "\n",
        "dirfmtT = \"%4d-%02d-%02d %02d:%02d:%02d\"\n",
        "dirfmt = \"/content/gdrive/My Drive/Bakalauras/Data/test/cluster/%4d-%02d-%02d %02d:%02d:%02d\"\n",
        "\n",
        "\n",
        "def operation_1(aplankalas, dvejetainiuNuotraukuVieta, log_chois = 0):\n",
        "  ##### Operacijos ir su seka vykdomasis kodas\n",
        "  global arSektiIrasus\n",
        "  arSektiIrasus = log_chois\n",
        "\n",
        "  # I-a operacija \n",
        "  start = time.time()\n",
        "\n",
        "  #aplankalas = \"/content/gdrive/My Drive/Bakalauras/Data/149ambers\"\n",
        "    \n",
        "  nuskaitytiOriginaliaNuotrauka_KonvertuotiIOriginaliaApkarpyta(aplankalas,dvejetainiuNuotraukuVieta)\n",
        "  end = time.time()\n",
        "  print(end - start, \"s\")\n",
        "\n",
        "# II-a operacija\n",
        "def operation2(folder_loacation, csv_location, log_chois = 0):\n",
        "    testi = True\n",
        "    global arSektiIrasus\n",
        "    arSektiIrasus = log_chois\n",
        "\n",
        "    try:\n",
        "      folder_lst = os.listdir(folder_loacation); \n",
        "    except FileNotFoundError:\n",
        "          print(\"Wrong binary nuotrauka location\")\n",
        "    else:\n",
        "\n",
        "      try:\n",
        "        p1 = csv_location.split(\".\")[0]\n",
        "        p2 = csv_location.split(\".\")[1]\n",
        "      except IndexError:\n",
        "        print(\"Wrong csv failoPavadinimas\")\n",
        "      else:\n",
        "        if not os.path.exists(os.path.dirname(csv_location)):\n",
        "          try:\n",
        "            os.makedirs(os.path.dirname(csv_location))\n",
        "          except FileNotFoundError:\n",
        "            testi = False\n",
        "        if testi:\n",
        "          sarasas = sorted( folder_lst, key=lambda a: int(a.split(\".\")[0].split(\"-\")[0]),reverse=False);\n",
        "\n",
        "          process = psutil.Process(os.getpid())\n",
        "          print(dydzioFormatas(process.memory_info().rss))\n",
        "\n",
        "          start = time.time()\n",
        "\n",
        "          df_F, df_main_F = main_data_preperation(folder_lst, folder_loacation, process, 0)\n",
        "\n",
        "          print(dydzioFormatas(process.memory_info().rss))   \n",
        "\n",
        "          display(df_F)\n",
        "          display(df_main_F)\n",
        "          \n",
        "          end = time.time()\n",
        "          print(end - start, \"s\")\n",
        "          operation_saveCsv(df_main_F , f\"{p1}_group.{p2}\")\n",
        "          operation_saveCsv(df_F , f\"{p1}_one.{p2}\")\n",
        "        else:\n",
        "          print(\"Can't create csv directory for specified file, path is incorrect.\")\n",
        "\n",
        "\n",
        "def operation_saveCsv(df_main_F, csv_location = '/content/gdrive/My Drive/Bakalauras/Data/CSV/ambers_export.csv',):\n",
        "    if not os.path.exists(os.path.dirname(csv_location)):\n",
        "      try:\n",
        "        os.makedirs(os.path.dirname(csv_location))\n",
        "      except FileNotFoundError:\n",
        "        print(\"Can't create directory, specified path is incorrect.\")\n",
        "      else:\n",
        "        df_main_F.to_csv (csv_location, index = False, header=True)\n",
        "    else: \n",
        "      df_main_F.to_csv (csv_location, index = False, header=True)\n",
        "\n",
        "def operation6_datastructure_correlation(csv_folder):\n",
        "  testi = True\n",
        "  try:\n",
        "    amber_csv_data = pd.read_csv(csv_folder) \n",
        "  except FileNotFoundError:\n",
        "    print(\"Wrong CSV location\")\n",
        "    testi = False\n",
        "  if testi:\n",
        "    amber_csv_data.info()\n",
        "\n",
        "    while True:\n",
        "      try:\n",
        "          t1 = str(input(\"Enter DataStruct end limiter ( or leave empty for default colums )\\n \"))\n",
        "          if t1 == \"\" and len(amber_csv_data.columns) <= 23:\n",
        "            t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\")\n",
        "          elif t1 == \"\" and  len(amber_csv_data.columns) > 25:\n",
        "                t1 = str(\"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\")\n",
        "      except ValueError:\n",
        "          if t1 == \"\" and  len(amber_csv_data.columns) <= 23:\n",
        "            t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\")\n",
        "          elif t1 == \"\" and  len(amber_csv_data.columns) > 25:\n",
        "                t1 = str(\"1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\")\n",
        "          else:\n",
        "            print(\"You entered not a number! Try again.\")\n",
        "            continue\n",
        "      else:\n",
        "          break \n",
        "    \n",
        "    map_s = map(converter,t1.split())\n",
        "    map_s = [x for x in map_s if x >= 0 and x <= len(amber_csv_data.columns)]\n",
        "    s_copy = amber_csv_data.iloc[:, list(map_s)] \n",
        "    \n",
        "    columnNames = s_copy.columns.values.tolist()\n",
        "\n",
        "    for dropNames in [string for string in columnNames if 'amber_cnt' in string or 'chaincode' in string or 'amber_picture' in string or 'amber_chain' in string or 'CDF' in string or 'major_axis_coordinates' in string or 'Filename' in string or 'amber_cnt' in string]:\n",
        "            s_copy = s_copy.drop([dropNames],axis = 1)\n",
        "\n",
        "    print(\"Headers\",list(amber_csv_data.columns.values),len(list(amber_csv_data.columns.values)))\n",
        "    print(\"Headers\",list(s_copy.columns.values))\n",
        "    if len(list(s_copy.columns.values)) > 1:\n",
        "      kaipKopija=((s_copy-s_copy.min())/(s_copy.max()-s_copy.min()))*20\n",
        "      corrMatrix = s_copy.corr()\n",
        "      fig, ax = plt.subplots(figsize=(40,40)) \n",
        "      sn.heatmap(corrMatrix, annot=True, linewidths=.5, ax=ax)\n",
        "      plt.show()\n",
        "      corrMatrix.to_csv(\"/content/gdrive/My Drive/Bakalauras/correlationCSV.csv\")\n",
        "    else:\n",
        "      print(\" !! Ammount of columns is too small, change column range !! \")\n",
        "\n",
        "\n",
        "def renameByRepetition(path, repetition):\n",
        "  if os.path.exists(path):\n",
        "    dirs = os.listdir(path)\n",
        "    dirs = natsort.natsorted(dirs,reverse=False)\n",
        "    i = 1;\n",
        "    j = 1;\n",
        "    for item in dirs:\n",
        "      old_file = pathlib.Path(os.path.join(path,item))\n",
        "      if os.path.exists(old_file):\n",
        "        fileType = item.split(\".\")[1]\n",
        "        new_file = os.path.join(path, f\"{i}-{j}.{fileType}\")\n",
        "        print(new_file, item)\n",
        "        os.rename(old_file, new_file)\n",
        "        if j >= repetition:\n",
        "          j = 1\n",
        "          i = i + 1 \n",
        "        else:\n",
        "          j = j + 1\n",
        "  else:\n",
        "    print(\"Path doesn't exist\")\n",
        "      \n",
        "#! usr/bin/python\n",
        "\n",
        "def converter(l):\n",
        "    try:\n",
        "        return ast.literal_eval(l)\n",
        "    except ValueError:\n",
        "        return l\n",
        "\n",
        "def DFT_slow(x):\n",
        "    \"\"\"Compute the discrete Fourier Transform of the 1D array x\"\"\"\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    N = x.shape[0]\n",
        "    n = np.arange(N)\n",
        "    k = n.reshape((N, 1))\n",
        "    M = np.exp(-2j * np.pi * k * n / N)\n",
        "    return np.dot(M, x)\n",
        "\n",
        "def operation5_loadcsv_Kmeans(csv_folder, cluster_loc = sorted_image_loc ,image_loc = binary_image_save_location, relearn_query = 0,  model_loc_folder = kmean_model_loc, normalization = 0, move_images = 0):#smaller_sized_image_loc): binary_image_save_location          n_klasteriuDydis, t1,t2\n",
        "    testi = True\n",
        "    try:\n",
        "      amber_csv_data = pd.read_csv(csv_folder) \n",
        "    except FileNotFoundError:\n",
        "      testi = False\n",
        "      print(f\"   !!! Alert !!!\\n   Wrong CSV location\\n   !!! Alert !!!\")\n",
        "\n",
        "    \n",
        "    if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "      try:\n",
        "        os.makedirs(os.path.dirname(cluster_loc))\n",
        "      except FileNotFoundError:\n",
        "        print(\"Wrong Clustered nuotrauka save location\")\n",
        "        testi = False\n",
        "    \n",
        "    if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "      try:\n",
        "        aplankaloSarasas = os.listdir(image_loc)\n",
        "      except FileNotFoundError:\n",
        "        print(\"Wrong original nuotrauka reading location\")\n",
        "        testi = False\n",
        "\n",
        "    if testi:\n",
        "\n",
        "      if relearn_query == 0:\n",
        "        while True:\n",
        "          try:\n",
        "              n_klasteriuDydis=int(input(\"Enter N cluster size for Kmean\\n \"))\n",
        "              if n_klasteriuDydis < 2 or n_klasteriuDydis >= len(amber_csv_data):\n",
        "                print(f\" cluster size should be: 2 <= n and n >= {len(amber_csv_data)}\")\n",
        "                continue\n",
        "          except ValueError:\n",
        "              print(\"You entered not a number! Try again.\")\n",
        "              continue\n",
        "          else:\n",
        "              break \n",
        "      elif relearn_query == 1:\n",
        "        \n",
        "        kVidurkiai =  pickle.load(open(f\"{model_loc_folder}/kmean.pkl\", \"rb\"))\n",
        "        kmean_settings = pickle.load(open(f\"{model_loc_folder}/kmean_settings.pkl\", \"rb\"))\n",
        "        t1 =  kmean_settings[0]\n",
        "        n_klasteriuDydis = len(kVidurkiai.cluster_centers_)\n",
        "        print(f\" Last model has this amount of clusters {n_klasteriuDydis}, from this file: {model_loc_folder}/kmean.pkl\")\n",
        "\n",
        "      amber_csv_data.info()\n",
        "      \n",
        "      if relearn_query == 0:\n",
        "        while True:\n",
        "          try:\n",
        "              t1 = str(input(\"Enter DataStruct end limiter ( or leave empty for default colums )\\n \"))\n",
        "              if t1 == \"\" and len(amber_csv_data.columns) <= 23:\n",
        "                t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\")\n",
        "              elif t1 == \"\" and  len(amber_csv_data.columns) > 25:\n",
        "                t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\")\n",
        "          except ValueError:\n",
        "              if t1 == \"\" and  len(amber_csv_data.columns) <= 23:\n",
        "                t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\")\n",
        "              elif t1 == \"\" and  len(amber_csv_data.columns) > 25:\n",
        "                t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\")\n",
        "              else:\n",
        "                print(\"You entered not a number! Try again.\")\n",
        "                continue\n",
        "          else:\n",
        "              break \n",
        "      elif relearn_query == 1:\n",
        "        print(\"Loaded DataStruct end limiter\", t1)\n",
        "      columnsInput = list(map(converter,t1.split()))\n",
        "\n",
        "      if len(columnsInput) == 1 and amber_csv_data.columns.values.tolist()[columnsInput[0]] == 'CDF':\n",
        "        arr = []\n",
        "        \n",
        "        kaipKopija = amber_csv_data.copy()\n",
        "        s_copies = amber_csv_data[\"CDF\"].to_numpy()\n",
        "                \n",
        "        for s_copy in s_copies:\n",
        "          scp1 = np.asarray(json.loads(s_copy), dtype=float)\n",
        "          fttOfCDF = np.fft.fft(json.loads(s_copy))\n",
        "          n = np.arange(fttOfCDF.shape[0])\n",
        "\n",
        "          arr.append(scp1.tolist())\n",
        "        \n",
        "        print(arr)\n",
        "        arr = np.array(arr)\n",
        "        v = arr   # \n",
        "        arr[:, :] = (v) / (v.sum())\n",
        "\n",
        "        # Normalizacija\n",
        "\n",
        "        if relearn_query == 0:\n",
        "          kVidurkiai = KMeans(n_clusters = n_klasteriuDydis)\n",
        "          yKvidurkiai = kVidurkiai.fit_predict(arr)\n",
        "          pickle.dump(kVidurkiai, open(f\"{model_loc_folder}/kmean.pkl\", \"wb\"))\n",
        "        elif relearn_query == 1:\n",
        "          # try:\n",
        "          yKvidurkiai = kVidurkiai.fit_predict(X)\n",
        "          \n",
        "        ##############################\n",
        "        kaipKopija.insert(0, 'Cluster', yKvidurkiai)\n",
        "\n",
        "        kaipKopija = (kaipKopija.sort_values(by=['Cluster']))\n",
        "    \n",
        "        aplankaloSarasas = os.listdir(image_loc)\n",
        "        print_image_list = sorted( aplankaloSarasas, key=lambda a: int(a.split(\".\")[0].split(\"-\")[0]),reverse=True )  \n",
        "                   \n",
        "        today = datetime.now()\n",
        "\n",
        "        if today.hour < 12:\n",
        "            aukst = \"00\"\n",
        "\n",
        "        else:\n",
        "            aukst = \"12\"\n",
        "\n",
        "        now = time.localtime()[0:6]\n",
        "        print(cluster_loc, now)\n",
        "        save_path = os.path.join(cluster_loc, dirfmtT)\n",
        "        save_path = save_path % now\n",
        "\n",
        "        if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "                os.makedirs(os.path.dirname(cluster_loc))\n",
        "        os.mkdir(save_path)\n",
        "        \n",
        "        for i in range(n_klasteriuDydis):\n",
        "          os.mkdir(os.path.join(save_path,str(i)+\"cluster\"))\n",
        "\n",
        "        for index, row in kaipKopija.iterrows():\n",
        "\n",
        "            if 'Filename' in row:\n",
        "              print(row['Cluster'], row['Filename'])\n",
        "              matching = str(row['Filename'])\n",
        "              tmp_path = pathlib.Path(os.path.join(image_loc,matching))\n",
        "              failoPatikra2 = pathlib.Path(tmp_path)\n",
        "              if failoPatikra2.exists() == True :\n",
        "                shutil.copy2(tmp_path, (os.path.join(save_path,str(row['Cluster'])+\"cluster\")) )\n",
        "\n",
        "            if not 'Filename' in row and 'amber_cnt' in row:\n",
        "              loc_str = str(row['amber_cnt'])+\"-\"\n",
        "              matching = [s for s in print_image_list if s.startswith(loc_str)]\n",
        "              print(\"Cluster: \", row['Cluster'], matching)\n",
        "              for img_loc in matching:\n",
        "                tmp_path = pathlib.Path(os.path.join(image_loc,img_loc))\n",
        "                failoPatikra2 = pathlib.Path(tmp_path)\n",
        "                if failoPatikra2.exists() == True :\n",
        "                  shutil.copy2(tmp_path, (os.path.join(save_path,str(row['Cluster'])+\"cluster\")) )\n",
        "\n",
        "        print(\"\\n\\nClustered data save path\", save_path, \"\\n\\n\")\n",
        "\n",
        "      else:\n",
        "\n",
        "        start = time.time()\n",
        "          \n",
        "        map_s = map(converter,t1.split())\n",
        "        map_s = [x for x in map_s if x >= 0 and x <= len(amber_csv_data.columns)]\n",
        "        s_copy = amber_csv_data.iloc[:, list(map_s)]\n",
        "\n",
        "        columnNames = s_copy.columns.values.tolist()\n",
        "\n",
        "        for dropNames in [string for string in columnNames if 'amber_cnt' in string or 'chaincode' in string or 'amber_picture' in string or 'amber_chain' in string or 'CDF' in string or 'major_axis_coordinates' in string or 'Filename' in string or 'amber_cnt' in string]:\n",
        "          s_copy = s_copy.drop([dropNames],axis = 1)\n",
        "        \n",
        "        if len(s_copy.columns) >= 1:\n",
        "          s_copy = s_copy.infer_objects()\n",
        "\n",
        "          kaipKopija = amber_csv_data.copy()\n",
        "          \n",
        "          # Normalizacija\n",
        "          \n",
        "          if relearn_query == 0:\n",
        "            smin = [];\n",
        "            smax = [];\n",
        "            for column in s_copy.columns:\n",
        "              smin.append(s_copy[column].min())\n",
        "              smax.append(s_copy[column].max())\n",
        "              s_copy[column] = (s_copy[column] -  s_copy[column].min() ) / (s_copy[column].max() -  s_copy[column].min() )  \n",
        "\n",
        "          elif relearn_query == 1:\n",
        "            smin = kmean_settings[2]\n",
        "            smax = kmean_settings[1]\n",
        "          \n",
        "            i = 0\n",
        "            for column in s_copy.columns:\n",
        "              s_copy[column] = (s_copy[column] - smin[i]) / (smax[i] - smin[i])    \n",
        "              i += 1\n",
        "                      \n",
        "          X = s_copy.iloc[:, :].values\n",
        "\n",
        "          if len(X) == 0:\n",
        "            print(f\"   !!! Alert !!!\\n   Wrong file or amount of values is too low \\n   !!! Alert !!!\")\n",
        "          elif n_klasteriuDydis < len(X) or n_klasteriuDydis > 2:\n",
        "            \n",
        "            if relearn_query == 0:\n",
        "              kVidurkiai = KMeans(n_clusters = n_klasteriuDydis)\n",
        "              yKvidurkiai = kVidurkiai.fit_predict(X)\n",
        "              pickle.dump(kVidurkiai, open(f\"{model_loc_folder}/kmean.pkl\", \"wb\"))\n",
        "              pickle.dump([t1, smax, smin], open(f\"{model_loc_folder}/kmean_settings.pkl\", \"wb\"))\n",
        "            elif relearn_query == 1:\n",
        "\n",
        "              yKvidurkiai = kVidurkiai.fit_predict(X)\n",
        "              \n",
        "            end = time.time()\n",
        "            print(end - start, \"s\")\n",
        "            kaipKopija.insert(0, 'Cluster', yKvidurkiai)\n",
        "\n",
        "            kaipKopija = (kaipKopija.sort_values(by=['Cluster']))\n",
        "           \n",
        "            aplankaloSarasas = os.listdir(image_loc)\n",
        "            print_image_list = sorted( aplankaloSarasas, key=lambda a: int(a.split(\".\")[0].split(\"-\")[0]),reverse=True )  \n",
        "             \n",
        "            today = datetime.now()\n",
        "\n",
        "            if today.hour < 12:\n",
        "                aukst = \"00\"\n",
        "\n",
        "            else:\n",
        "                aukst = \"12\"\n",
        "\n",
        "            now = time.localtime()[0:6]\n",
        "            print(cluster_loc, now)\n",
        "            save_path = os.path.join(cluster_loc, dirfmtT)\n",
        "            save_path = save_path % now\n",
        "\n",
        "            if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "              try:\n",
        "                os.makedirs(os.path.dirname(cluster_loc))\n",
        "              except FileNotFoundError:\n",
        "                print(\"Wrong Clustered nuotrauka save location\")\n",
        "                testi = False\n",
        "\n",
        "            if testi:\n",
        "              os.mkdir(save_path)\n",
        "              if move_images == 0: \n",
        "                for i in range(n_klasteriuDydis):\n",
        "                  os.mkdir(os.path.join(save_path,str(i)+\"cluster\"))\n",
        "                \n",
        "                for index, row in kaipKopija.iterrows():\n",
        "\n",
        "                    if 'Filename' in row:\n",
        "\n",
        "                      print(row['Cluster'], row['Filename'])\n",
        "                      matching = str(row['Filename'])\n",
        "                      tmp_path = pathlib.Path(os.path.join(image_loc,matching))\n",
        "                      failoPatikra2 = pathlib.Path(tmp_path)\n",
        "\n",
        "                      if failoPatikra2.exists() == True :\n",
        "                        shutil.copy2(tmp_path, (os.path.join(save_path,str(row['Cluster'])+\"cluster\")) )\n",
        "\n",
        "                    if not 'Filename' in row and 'amber_cnt' in row:\n",
        "\n",
        "                      loc_str = str(row['amber_cnt'])+\"-\"\n",
        "                      matching = [s for s in print_image_list if s.startswith(loc_str)]\n",
        "                      print(\"Cluster: \", row['Cluster'], matching)\n",
        "\n",
        "                      for img_loc in matching:\n",
        "                        tmp_path = pathlib.Path(os.path.join(image_loc,img_loc))\n",
        "                        failoPatikra2 = pathlib.Path(tmp_path)\n",
        "\n",
        "                        if failoPatikra2.exists() == True :\n",
        "                          shutil.copy2(tmp_path, (os.path.join(save_path,str(row['Cluster'])+\"cluster\")) )\n",
        "\n",
        "                print(\"\\n\\nClustered data save path\", save_path, \"\\n\\n\")\n",
        "            \n",
        "\n",
        "            p1 = save_path + \"/\" +csv_folder.split(\"/\")[-1].split(\".\")[0] + \"_results.csv\"\n",
        "            print(\"\\n\\nClustered csv details saved in\", p1 , \"\\n\\n\")\n",
        "            operation_saveCsv(kaipKopija , f\"{p1}\")\n",
        "            ############################################\n",
        "            # Silhouette \n",
        "\n",
        "            print(\"\\n\\nThis Silhouette coefficient dimension tells, how points in one cluster are far away from another cluster;\", \"\\nThe silhouette coefficient of whole cluster is the average of all clusters silhouette coefficients, the value can differ between [-1,1];\")\n",
        "            print(\" - A value close to coefficient +1 indicates that the clusters are far from each other\")\n",
        "            print(\" - A value close to coefficient  0 indicates that the clusters are close to each other and they might overlap\")\n",
        "            print(\" - A value close to coefficient -1 indicates that certain points have been assigned incorrectly, which mignt be not for that cluster.\\n\")\n",
        "\n",
        "            siluetoVidurkis = siluetoTaskai(X, yKvidurkiai)\n",
        "            print(\"For n_clusters =\", n_klasteriuDydis,\n",
        "                  \"The average silhouette score is: \", siluetoVidurkis,\" (marked in red dashed line)\")\n",
        "\n",
        "            # Apskaiciuojami sipuetai sio pavyzdzio\n",
        "            pavyzdzioSiluetoReiksmes = silhouette_samples(X, yKvidurkiai)\n",
        "\n",
        "            y_apatinis = 10\n",
        "            for i in range(n_klasteriuDydis):\n",
        "\n",
        "                ith_klasteriopavyzdzioSiluetoReiksmes = \\\n",
        "                pavyzdzioSiluetoReiksmes[yKvidurkiai == i]\n",
        "\n",
        "                ith_klasteriopavyzdzioSiluetoReiksmes.sort()\n",
        "\n",
        "                klasterioDydis_i = ith_klasteriopavyzdzioSiluetoReiksmes.shape[0]\n",
        "                y_virsutinis = y_apatinis + klasterioDydis_i\n",
        "\n",
        "                color = cm.nipy_spectral(float(i) / n_klasteriuDydis)\n",
        "                plt.fill_betweenx(np.arange(y_apatinis, y_virsutinis),\n",
        "                                  0, ith_klasteriopavyzdzioSiluetoReiksmes,\n",
        "                                  facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "                plt.text(-0.05, y_apatinis + 0.5 * klasterioDydis_i, str(i))\n",
        "\n",
        "                y_apatinis = y_virsutinis + 10  \n",
        "\n",
        "            plt.xlabel(\"The silhouette coefficient values\")\n",
        "            plt.ylabel(\"Cluster label\")\n",
        "\n",
        "            plt.axvline(x = siluetoVidurkis, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "            plt.yticks([])  \n",
        "            plt.xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "            plt.suptitle((\"Silhouette analysis of KMeans clustering \"\n",
        "                          \"with n_clusters = %d\" % n_klasteriuDydis),\n",
        "                        fontsize=14, fontweight='bold')\n",
        "            plt.show()\n",
        "            ############################################\n",
        "            # Alkunes metodo inercija\n",
        "            if len(X) >= n_klasteriuDydis:\n",
        "              distortions = []\n",
        "              if len(X) >= n_klasteriuDydis + n_klasteriuDydis:\n",
        "                K = range(1, (n_klasteriuDydis + n_klasteriuDydis ))\n",
        "              else: \n",
        "                K = range(1, (n_klasteriuDydis ))\n",
        "              print(\"\\n\\nInertia graph. Which shows how far away are clusters between each other;\", \"\\nIt is suggested to avoid over-clustering and to choose the number of clusters that is close to the rise of the inertia curve;\\n\")\n",
        "              distortions = []\n",
        "\n",
        "              for k in K:\n",
        "                  kVidurkiuModelis = KMeans(n_clusters = k)#, init = 'k-means++', random_state = 42) #(n_clusters=k) # (n_clusters = n_klasteriuDydis, init = 'k-means++', random_state = 42)\n",
        "                  kVidurkiuModelis.fit(X)\n",
        "                  distortions.append(kVidurkiuModelis.inertia_)\n",
        "\n",
        "              plt.figure(figsize=(8,4))\n",
        "              plt.plot(K, distortions, 'bx-')\n",
        "              plt.xlabel('k - amount of clusters')\n",
        "              plt.ylabel('Inertia')\n",
        "              plt.title('The Elbow Method, which shows the optimal k')\n",
        "              plt.show()\n",
        "              \n",
        "            else:\n",
        "              print(\"Cant display Elbow method analysis, the amount of samples is too low\")\n",
        "            ############################################\n",
        "          else:\n",
        "            print(f\"   !!! Alert !!!\\n   You need to change N - cluster size [2,{len(X)}]\\n   !!! Alert !!!\")\n",
        "        else:\n",
        "          print(f\"   !!! Alert !!!\\n   You need to enter more avaible values\\n {len(s_copy.columns)}  !!! Alert !!!\")\n",
        "\n",
        "def operation_SOM(csv_folder, n_klasteriuDydis, cluster_loc = sorted_image_loc ,image_loc = binary_image_save_location):\n",
        "  arr = []\n",
        "  amber_csv_data = pd.read_csv(csv_folder) \n",
        "  amber_csv_data = amber_csv_data.sort_values(by=['amber_cnt'])\n",
        "  print(amber_csv_data.columns.values.tolist())\n",
        "  print(amber_csv_data.columns.values.tolist()[21])\n",
        "  print(list(amber_csv_data.columns.values.tolist()))\n",
        "  print(list(amber_csv_data.columns.values.tolist())[21])\n",
        "  if amber_csv_data.columns.values.tolist()[21] == 'CDF1':\n",
        "    print(\"++++++++++++++++++++++\")\n",
        "  kaipKopija = amber_csv_data.copy()\n",
        "  \n",
        "  s_copies = amber_csv_data[\"CDF1\"].to_numpy()\n",
        "  i = 0\n",
        "  for s_copy in s_copies:\n",
        "    arr1 = json.loads(s_copy)\n",
        "\n",
        "    scp1 = np.asarray(arr1, dtype=float)\n",
        "    fttOfCDF = np.fft.fft(arr1)\n",
        "    n = np.arange(fttOfCDF.shape[0])\n",
        "\n",
        "    plt.plot(n, fttOfCDF, '-bo')\n",
        "    plt.title(\"Furje Transformacija\")\n",
        "    plt.ylabel(\"Normalizuotų Furjė koeficientų dydis\")\n",
        "    plt.xlabel(\"Dažnis\")\n",
        "    plt.show()\n",
        "    \n",
        "    print(arr1)\n",
        "    print(n)\n",
        "    print(i)\n",
        "    \n",
        "    plt.plot(n, arr1)\n",
        "    plt.title(\"CDF - Centroidų atstumų funkcijos atstumai\")\n",
        "    plt.xlabel(\"Iteracija\")\n",
        "    plt.ylabel(\"Atstumas\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "    i = i + 1\n",
        "    arr.append(scp1.tolist())\n",
        "  \n",
        "  print(arr)\n",
        "  arr = np.array(arr)\n",
        "  v = arr   # \n",
        "  arr[:, :] = (v) / (v.sum())\n",
        "    \n",
        "  kVidurkiai = KMeans(n_clusters = n_klasteriuDydis)\n",
        "\n",
        "  yKvidurkiai = kVidurkiai.fit_predict(arr)\n",
        "\n",
        "  ##############################\n",
        "\n",
        "  kaipKopija.insert(0, 'Cluster', yKvidurkiai)\n",
        "  kaipKopija = (kaipKopija.sort_values(by=['Cluster']))\n",
        "\n",
        "  aplankaloSarasas = os.listdir(image_loc)\n",
        "  print_image_list = sorted( aplankaloSarasas, key=lambda a: int(a.split(\".\")[0].split(\"-\")[0]),reverse=True )  \n",
        "      \n",
        "  today = datetime.now()\n",
        "\n",
        "  if today.hour < 12:\n",
        "      aukst = \"00\"\n",
        "  else:\n",
        "      aukst = \"12\"\n",
        "\n",
        "  now = time.localtime()[0:6]\n",
        "  print(cluster_loc, now)\n",
        "  save_path = os.path.join(cluster_loc, dirfmtT)\n",
        "  save_path = save_path % now\n",
        "  if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "          os.makedirs(os.path.dirname(cluster_loc))\n",
        "  os.mkdir(save_path)\n",
        "  \n",
        "  for i in range(n_klasteriuDydis):\n",
        "    os.mkdir(os.path.join(save_path,str(i)+\"cluster\"))\n",
        "\n",
        "  for index, row in kaipKopija.iterrows():\n",
        "\n",
        "      if 'Filename' in row:\n",
        "        print(row['Cluster'], row['Filename'])\n",
        "        matching = str(row['Filename'])\n",
        "        tmp_path = pathlib.Path(os.path.join(image_loc,matching))\n",
        "        failoPatikra2 = pathlib.Path(tmp_path)\n",
        "        if failoPatikra2.exists() == True :\n",
        "          shutil.copy2(tmp_path, (os.path.join(save_path,str(row['Cluster'])+\"cluster\")) )\n",
        "\n",
        "      if not 'Filename' in row and 'amber_cnt' in row:\n",
        "        loc_str = str(row['amber_cnt'])+\"-\"\n",
        "        matching = [s for s in print_image_list if s.startswith(loc_str)]\n",
        "        print(\"Cluster: \", row['Cluster'], matching)\n",
        "        for img_loc in matching:\n",
        "          tmp_path = pathlib.Path(os.path.join(image_loc,img_loc))\n",
        "          failoPatikra2 = pathlib.Path(tmp_path)\n",
        "          if failoPatikra2.exists() == True :\n",
        "            shutil.copy2(tmp_path, (os.path.join(save_path,str(row['Cluster'])+\"cluster\")) )\n",
        "\n",
        "  print(\"\\n\\nClustered data save path\", save_path, \"\\n\\n\")\n",
        "\n",
        "  \n",
        "def operation6_loadcsv_SOM(csv_folder, cluster_loc = sorted_image_loc ,image_loc = binary_image_save_location, relearn_query = 0,  model_loc_folder = kmean_model_loc, normalization = 0, move_images = 0):#smaller_sized_image_loc): binary_image_save_location          n_klasteriuDydis, t1,t2\n",
        "    testi = True\n",
        "    try:\n",
        "      amber_csv_data = pd.read_csv(csv_folder) \n",
        "    except FileNotFoundError:\n",
        "      testi = False\n",
        "      print(f\"   !!! Alert !!!\\n   Wrong CSV location\\n   !!! Alert !!!\")\n",
        "\n",
        "    \n",
        "    if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "      try:\n",
        "        os.makedirs(os.path.dirname(cluster_loc))\n",
        "      except FileNotFoundError:\n",
        "        print(\"Wrong Clustered nuotrauka save location\")\n",
        "        testi = False\n",
        "    \n",
        "    if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "      try:\n",
        "        aplankaloSarasas = os.listdir(image_loc)\n",
        "      except FileNotFoundError:\n",
        "        print(\"Wrong original nuotrauka reading location\")\n",
        "        testi = False\n",
        "\n",
        "    if testi:\n",
        "      if relearn_query == 0:\n",
        "        while True:\n",
        "          try:\n",
        "              n_map_size=int(input(\"Enter N size for SOM\\n \"))\n",
        "          except ValueError:\n",
        "              print(\"You entered not a number! Try again.\")\n",
        "              continue\n",
        "          else:\n",
        "              break \n",
        "        while True:\n",
        "          try:\n",
        "              m_map_size=int(input(\"Enter M size for SOM\\n \"))\n",
        "          except ValueError:\n",
        "              print(\"You entered not a number! Try again.\")\n",
        "              continue\n",
        "          else:\n",
        "              break \n",
        "      elif relearn_query == 1:\n",
        "      #  Permokinti algoritma per nauja su naujais duomenimis isemant pickle duomenis ir idedant i SOM\n",
        "\n",
        "        som =  pickle.load(open(f\"{model_loc_folder}/som.pkl\", \"rb\"))\n",
        "        som_settings = pickle.load(open(f\"{model_loc_folder}/som_settings.pkl\", \"rb\"))\n",
        "        t1 =  som_settings[0]\n",
        "        \n",
        "        n_map_size = som_settings[3]\n",
        "        m_map_size = som_settings[4]\n",
        "        print(f\" This SOM map model dimensions is {m_map_size}x{n_map_size}, from this file: {model_loc_folder}/som.pkl\")\n",
        "\n",
        "      amber_csv_data.info()\n",
        "            \n",
        "      if relearn_query == 0:\n",
        "        while True:\n",
        "          try:\n",
        "              t1 = str(input(\"Enter DataStruct end limiter ( or leave empty for default colums )\\n \"))\n",
        "              if t1 == \"\" and len(amber_csv_data.columns) <= 23:\n",
        "                t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\")\n",
        "              elif t1 == \"\" and  len(amber_csv_data.columns) > 25:\n",
        "                t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\")\n",
        "          except ValueError:\n",
        "              if t1 == \"\" and  len(amber_csv_data.columns) <= 23:\n",
        "                t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\")\n",
        "              elif t1 == \"\" and  len(amber_csv_data.columns) > 25:\n",
        "                t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\")\n",
        "              else:\n",
        "                print(\"You entered not a number! Try again.\")\n",
        "                continue\n",
        "          else:\n",
        "              break \n",
        "      elif relearn_query == 1:\n",
        "        print(\"Loaded DataStruct end limiter\", t1)\n",
        "      start = time.time()\n",
        "      columnsInput = list(map(converter,t1.split()))\n",
        "      if len(columnsInput) > 1 and amber_csv_data.columns.values.tolist()[columnsInput[0]] != 'CDF':\n",
        "              \n",
        "        map_s = map(converter,t1.split())\n",
        "        map_s = [x for x in map_s if x >= 0 and x <= len(amber_csv_data.columns)]\n",
        "        s_copy = amber_csv_data.iloc[:, list(map_s)]#-5:-2] # df.infer_objects()\n",
        "        columnNames = s_copy.columns.values.tolist()\n",
        "\n",
        "        for dropNames in [string for string in columnNames if 'amber_cnt' in string or 'chaincode' in string or 'amber_picture' in string or 'amber_chain' in string or 'CDF' in string or 'major_axis_coordinates' in string or 'Filename' in string or 'amber_cnt' in string]:\n",
        "          s_copy = s_copy.drop([dropNames],axis = 1)\n",
        "        \n",
        "        if len(s_copy.columns) >= 1:\n",
        "          s_copy = s_copy.infer_objects()\n",
        "          kaipKopija = amber_csv_data.copy()\n",
        "\n",
        "          # min-max normalizavimas \n",
        "          # Normalizacija\n",
        "\n",
        "          if relearn_query == 0:\n",
        "            smin = [];\n",
        "            smax = [];\n",
        "            for column in s_copy.columns:\n",
        "              smin.append(s_copy[column].min())\n",
        "              smax.append(s_copy[column].max())\n",
        "              s_copy[column] = (s_copy[column] -  s_copy[column].min() ) / (s_copy[column].max() -  s_copy[column].min() )  \n",
        "          elif relearn_query == 1:\n",
        "            smin = som_settings[2]\n",
        "            smax = som_settings[1]\n",
        "            i = 0\n",
        "            for column in s_copy.columns:\n",
        "              s_copy[column] = (s_copy[column] - smin[i]) / (smax[i] - smin[i])    \n",
        "              i += 1\n",
        "          \n",
        "          X = s_copy.iloc[:, :].values\n",
        "\n",
        "          if len(X) == 0:\n",
        "            print(f\"   !!! Alert !!!\\n   Wrong file or amount of values is too low \\n   !!! Alert !!!\")\n",
        "\n",
        "          elif n_map_size > 2 and  m_map_size > 1 and len(X) > 0:\n",
        "\n",
        "            if relearn_query == 0:\n",
        "              som = SOM(m=n_map_size , n=m_map_size, dimensija=len(s_copy.columns))\n",
        "              '''\n",
        "              m - tai vetrikalios pozicijos SOM žemėlapio dimensija;\n",
        "              n - tai horizontalios padeties SOM žemėlapio dimensija;\n",
        "              dimensija - tai iškirtinių savybių (stulpelių) kiekis;\n",
        "              sigma = 1 - tai pasirinktinas parametras keičiantis regavimus į skirtingus duomenų svorius;\n",
        "              lr = 1 - tai žingsnio dydis atnaujinant SOM svorius;\n",
        "              max_iter = 3000 - tai parametras nusakantis po kiek iteracijų nustoti trenitavimą.\n",
        "              '''\n",
        "              som.fit(X)\n",
        "              '''\n",
        "              fit(X, epochs=1, shuffle=True)\n",
        "              epochs - tai kiek kartų kartoti pradinius duomenis.\n",
        "              shuffle - tai pasirinkimas ar sumaišyti duomenis ar ne prieš perduodant duomenis.\n",
        "\n",
        "\n",
        "              '''\n",
        "              y_som = som.predict(X)\n",
        "\n",
        "              pickle.dump(som, open(f\"{model_loc_folder}/som.pkl\", \"wb\"))\n",
        "              pickle.dump([t1, smax, smin, n_map_size, m_map_size ], open(f\"{model_loc_folder}/som_settings.pkl\", \"wb\"))\n",
        "            elif relearn_query == 1:\n",
        "              som.fit(X)\n",
        "              y_som = som.predict(X)\n",
        "              pickle.dump(som, open(f\"{model_loc_folder}/som.pkl\", \"wb\"))\n",
        "          \n",
        "            kaipKopija.insert(0, 'Cluster', y_som)\n",
        "            kaipKopija = (kaipKopija.sort_values(by=['Cluster']))\n",
        "\n",
        "            \n",
        "            end = time.time()\n",
        "            print(end - start, \"s\")\n",
        "\n",
        "            aplankaloSarasas = os.listdir(image_loc)\n",
        "            print_image_list = sorted( aplankaloSarasas, key=lambda a: int(a.split(\".\")[0].split(\"-\")[0]),reverse=True )  \n",
        "            \n",
        "            today = datetime.now()\n",
        "\n",
        "            if today.hour < 12:\n",
        "                aukst = \"00\"\n",
        "            else:\n",
        "                aukst = \"12\"\n",
        "\n",
        "            now = time.localtime()[0:6]\n",
        "            print(cluster_loc, now)\n",
        "            save_path = os.path.join(cluster_loc, dirfmtT)\n",
        "            save_path = save_path % now\n",
        "\n",
        "            if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "              try:\n",
        "                os.makedirs(os.path.dirname(cluster_loc))\n",
        "              except FileNotFoundError:\n",
        "                print(\"Wrong Clustered nuotrauka save location\")\n",
        "                testi = False\n",
        "\n",
        "            if testi:\n",
        "              os.mkdir(save_path)\n",
        "              if move_images == 0: \n",
        "                for row in kaipKopija['Cluster'].unique():\n",
        "                  os.mkdir(os.path.join(save_path,str(row)+\"cluster\"))\n",
        "                \n",
        "                for index, row in kaipKopija.iterrows():\n",
        "\n",
        "                    if 'Filename' in row:\n",
        "                      print(row['Cluster'], row['Filename'])\n",
        "                      matching = str(row['Filename'])\n",
        "                      tmp_path = pathlib.Path(os.path.join(image_loc,matching))\n",
        "                      failoPatikra2 = pathlib.Path(tmp_path)\n",
        "                      if failoPatikra2.exists() == True :\n",
        "                        shutil.copy2(tmp_path, (os.path.join(save_path,str(row['Cluster'])+\"cluster\")) )\n",
        "\n",
        "                    if not 'Filename' in row and 'amber_cnt' in row:\n",
        "                      loc_str = str(row['amber_cnt'])+\"-\"\n",
        "                      matching = [s for s in print_image_list if s.startswith(loc_str)]\n",
        "                      print(\"Cluster: \", row['Cluster'], matching)\n",
        "                      for img_loc in matching:\n",
        "                        tmp_path = pathlib.Path(os.path.join(image_loc,img_loc))\n",
        "                        failoPatikra2 = pathlib.Path(tmp_path)\n",
        "                        if failoPatikra2.exists() == True :\n",
        "                          shutil.copy2(tmp_path, (os.path.join(save_path,str(row['Cluster'])+\"cluster\")) )\n",
        "                print(\"\\n\\nClustered data save path\", save_path, \"\\n\\n\")\n",
        "\n",
        "            p1 = save_path + \"/\" +csv_folder.split(\"/\")[-1].split(\".\")[0] + \"_results.csv\"\n",
        "            print(\"\\n\\nClustered csv details saved in\", p1 , \"\\n\\n\")\n",
        "            operation_saveCsv(kaipKopija , f\"{p1}\")\n",
        "\n",
        "          else:\n",
        "            print(f\"   !!! Alert !!!\\n   You need to change N - cluster size [2,{len(X)}]\\n   !!! Alert !!!\")\n",
        "\n",
        "        else:\n",
        "          print(f\"   !!! Alert !!!\\n   You need to enter more avaible values\\n {len(s_copy.columns)}  !!! Alert !!!\")\n",
        "\n",
        "def main():\n",
        "  print(\"Welcome to amber clustering - sorting by shape system\\n\\nPick from avaible operations:\\n\\n 1 - Reduce size of raw images;\")\n",
        "  print(\" 2 - Rename all images in pattern;\")\n",
        "  print(\" 3 - Convert raw images to BINARY/Greyscale images;\")\n",
        "  print(\" 4 - Create new Data Structure from binary images;\")\n",
        "  print(\" 5 - Sort Data Structure CSV, with K-Means;\")\n",
        "  print(\" 6 - Display data structure in Correlation table;\")\n",
        "  print(\" 7 - Sort Ambers - Data Structure CSV, with SOM;\")\n",
        "  print(\" 0 - Exit\")\n",
        "\n",
        "  while True:\n",
        "      try:\n",
        "          print(\"\")\n",
        "          pasirinktaOperacija= int(input(\"What operation you want to do?\\n \"))\n",
        "\n",
        "      except ValueError:\n",
        "          print(\"You entered not a number! Try again.\")\n",
        "          continue\n",
        "\n",
        "      else:\n",
        "          break \n",
        "\n",
        "  while pasirinktaOperacija != 0:\n",
        "      if pasirinktaOperacija == 1:\n",
        "            while True:\n",
        "              try:\n",
        "                resize_ratio=float(input(f\"Enter nuotrauka resize ratio: (ex.: 0.5 - for 2 times smaller nuotrauka, 0.25 - for 4 times smaller nuotrauka )\\n\"))\n",
        "                \n",
        "                if resize_ratio <= 0 and resize_ratio >= 1:\n",
        "                  print(\"You entered incorrect ratio\")\n",
        "                  continue\n",
        "\n",
        "              except ValueError:\n",
        "                print(\"You entered not a number! Try again.\")\n",
        "                continue\n",
        "\n",
        "              else:\n",
        "                break \n",
        "            \n",
        "            path=str(input(f\"Enter aplankalas location from where to read RAW images, or leave empty for default: ( {raw_image_loc} )\\n\"))\n",
        "            \n",
        "            if path == \"\":\n",
        "              path = raw_image_loc\n",
        "\n",
        "            save_path=str(input(f\"Enter aplankalas location where to save formatted images, or leave empty for default: ( {smaller_sized_image_loc} )\\n\"))\n",
        "            \n",
        "            if save_path == \"\":\n",
        "              save_path = smaller_sized_image_loc\n",
        "              \n",
        "            resize_aspect_fit(resize_ratio, path, save_path )\n",
        "\n",
        "      elif pasirinktaOperacija == 2:\n",
        "\n",
        "            rename_folder=str(input(f\"Enter what aplankalas to rename, leave empty field for default: ( {csv_rename_loc} )\\n\"))\n",
        "          \n",
        "            if rename_folder == \"\":\n",
        "                rename_folder = csv_rename_loc    \n",
        "\n",
        "            renameByRepetition(rename_folder, 3)# pattern)\n",
        "\n",
        "      elif pasirinktaOperacija == 3:\n",
        "            aplankalas=str(input(f\"Enter nuotrauka aplankalas location or leave empty for default: ( {smaller_sized_image_loc} )\\n\"))\n",
        "            \n",
        "            if aplankalas == \"\":\n",
        "              aplankalas = smaller_sized_image_loc\n",
        "\n",
        "            dvejetainiuNuotraukuVieta=str(input(f\"Enter where to save binary images - aplankalas location or leave empty field for default: ( {binary_image_save_location} )\\n\"))\n",
        "            \n",
        "            if dvejetainiuNuotraukuVieta == \"\":\n",
        "              dvejetainiuNuotraukuVieta = binary_image_save_location\n",
        "\n",
        "            operation_1(aplankalas, dvejetainiuNuotraukuVieta )\n",
        "\n",
        "      elif pasirinktaOperacija == 4:\n",
        "            global arSektiIrasus\n",
        "            folder_loacation=str(input(f\"Enter binary nuotrauka aplankalas location or leave empty for default: ( {binary_image_save_location} )\\n\"))\n",
        "            \n",
        "            if folder_loacation == \"\":\n",
        "              folder_loacation=binary_image_save_location\n",
        "\n",
        "            csv_save_locat=str(input(f\"Enter CSV data structure failoPavadinimas, and file path, or leave empty for default: ( {csv_save_loc_csv} )\\n\"))\n",
        "            \n",
        "            if csv_save_locat == \"\":\n",
        "              csv_save_locat=csv_save_loc_csv\n",
        "\n",
        "            while True:\n",
        "              try:\n",
        "                  log_data =int(input(\"Enter 1 - to print calculation log; 0 - without log. \\n \"))\n",
        "              except ValueError:\n",
        "                  log_data = 0\n",
        "                  print(\"You chosen not to print log.\")\n",
        "                  break\n",
        "                  continue\n",
        "              else:\n",
        "                  if log_data != 0:\n",
        "                    print(\"You chosen to print log.\")\n",
        "                  else:\n",
        "                    print(\"You chosen not to print log.\")\n",
        "                  break \n",
        "\n",
        "            operation2(folder_loacation,csv_save_locat, log_data)\n",
        "            \n",
        "            arSektiIrasus = 0\n",
        "\n",
        "      elif pasirinktaOperacija == 5:\n",
        "            n_clusters = 1\n",
        "          \n",
        "            csv_folder=str(input(f\"Enter from where to read CSV  (or leave empty field for default: Opt. 1: {csv_save_loc_one} )  ( Opt. 2: {csv_save_loc_group} )\\n\\\n",
        "                                                         (Opt. 3: {csv_save_loc_one_orig} )  ( Opt. 4: {csv_save_loc_group_orig} )\\n\"))\n",
        "            if csv_folder == \"\" or csv_folder == \"1\":\n",
        "              csv_folder = csv_save_loc_one\n",
        "\n",
        "            elif  csv_folder == \"2\" :\n",
        "              csv_folder = csv_save_loc_group\n",
        "\n",
        "            elif  csv_folder == \"3\" :\n",
        "              csv_folder = csv_save_loc_one_orig\n",
        "\n",
        "            elif  csv_folder == \"4\" :\n",
        "              csv_folder = csv_save_loc_group_orig\n",
        "\n",
        "            while True:\n",
        "              try:\n",
        "                  move_img =int(input(\"Enter 0 - to copy sorted amber images, or 1 - to do nothing with images. (default 0) \\n \"))\n",
        "\n",
        "              except ValueError:\n",
        "                  move_img = 0\n",
        "                  print(\"\\n You chosen to copy sorted amber images.\")\n",
        "                  break\n",
        "                  continue\n",
        "\n",
        "              else:\n",
        "                if move_img == 1:\n",
        "                  print(\"You chosen to do nothing with images.\")\n",
        "\n",
        "                else:\n",
        "                  move_img = 0\n",
        "                  print(\"\\n You chosen to copy sorted amber images.\")\n",
        "\n",
        "                break \n",
        "\n",
        "            orig_img_loc=str(input(f\"Enter from where to copy images to new location: (Opt. 1: {binary_image_save_location} ) (Opt. 2: {binary_image_save_location_orig} )\\n\"))\n",
        "            \n",
        "            if orig_img_loc == \"\" or orig_img_loc == \"1\":\n",
        "              orig_img_loc = binary_image_save_location\n",
        "\n",
        "            elif orig_img_loc == \"2\":\n",
        "              orig_img_loc = binary_image_save_location_orig\n",
        "\n",
        "            clusteded_d_folder=str(input(f\"Enter where to save new Clustered data: (Opt1. : {sorted_image_loc} ) (Opt2. : {sorted_image_loc_orig} )\\n\"))\n",
        "            if clusteded_d_folder == \"\" or clusteded_d_folder == \"1\":\n",
        "              clusteded_d_folder = sorted_image_loc\n",
        "\n",
        "            elif clusteded_d_folder == \"2\":\n",
        "              clusteded_d_folder = sorted_image_loc_orig\n",
        "            \n",
        "            model_loc_folder=str(input(f\"Enter from where to read Kmean Model or leave empty field for default Opt. 1. ( Opt. 1: {kmean_model_loc} )  (Opt. 2:  )\\n\")) # K-Mean-MODEL\n",
        "            if model_loc_folder == \"\" or model_loc_folder == \"1\":\n",
        "              model_loc_folder = kmean_model_loc\n",
        "            \n",
        "            while True:\n",
        "              try:\n",
        "                  relearn_query =int(input(\"Enter 0 - to create new k-mean model, or 1 - To reuse existing k-mean model. (default 0) \\n \"))\n",
        "\n",
        "              except ValueError:\n",
        "                  relearn_query = 0\n",
        "                  print(\"\\n You chosen to create new machine learning model.\")\n",
        "                  break\n",
        "                  continue\n",
        "              else:\n",
        "                  if relearn_query == 1:\n",
        "                    print(\"You chosen to reuse existing k-mean machine learning model.\")\n",
        "                  else:\n",
        "                    relearn_query = 0\n",
        "                    print(\"\\n You chosen to create new machine learning model.\")\n",
        "                  break \n",
        "\n",
        "            operation5_loadcsv_Kmeans(csv_folder, clusteded_d_folder, orig_img_loc, relearn_query, model_loc_folder, move_images = move_img)\n",
        "      \n",
        "      elif pasirinktaOperacija == 6:\n",
        "                \n",
        "          csv_folder=str(input(f\"Enter from where to read CSV  (or leave empty field for default: Opt. 1: {csv_save_loc_one} )  ( Opt. 2: {csv_save_loc_group} )\\n\\\n",
        "                                                        (Opt. 3: {csv_save_loc_one_orig} )  ( Opt. 4: {csv_save_loc_group_orig} )\\n\"))\n",
        "          if csv_folder == \"\" or csv_folder == \"1\":\n",
        "            csv_folder = csv_save_loc_one\n",
        "\n",
        "          elif  csv_folder == \"2\" :\n",
        "            csv_folder = csv_save_loc_group\n",
        "\n",
        "          elif  csv_folder == \"3\" :\n",
        "            csv_folder = csv_save_loc_one_orig\n",
        "\n",
        "          elif  csv_folder == \"4\" :\n",
        "            csv_folder = csv_save_loc_group_orig\n",
        "\n",
        "          operation6_datastructure_correlation(csv_folder)\n",
        "\n",
        "      elif pasirinktaOperacija == 7:\n",
        "        \n",
        "            csv_folder=str(input(f\"Enter from where to read CSV  (or leave empty field for default: Opt. 1: {csv_save_loc_one} )  ( Opt. 2: {csv_save_loc_group} )\\n\\\n",
        "                                                         (Opt. 3: {csv_save_loc_one_orig} )  ( Opt. 4: {csv_save_loc_group_orig} )\\n\"))\n",
        "            if csv_folder == \"\" or csv_folder == \"1\":\n",
        "              csv_folder = csv_save_loc_one\n",
        "\n",
        "            elif  csv_folder == \"2\" :\n",
        "              csv_folder = csv_save_loc_group\n",
        "\n",
        "            elif  csv_folder == \"3\" :\n",
        "              csv_folder = csv_save_loc_one_orig\n",
        "\n",
        "            elif  csv_folder == \"4\" :\n",
        "              csv_folder = csv_save_loc_group_orig\n",
        "\n",
        "            while True:\n",
        "              try:\n",
        "                  move_img =int(input(\"Enter 0 - to copy sorted amber images, or 1 - to do nothing with images. (default 0) \\n \"))\n",
        "              except ValueError:\n",
        "                  move_img = 0\n",
        "                  print(\"\\n You chosen to copy sorted amber images.\")\n",
        "                  break\n",
        "                  continue\n",
        "              else:\n",
        "                if move_img == 1:\n",
        "                  print(\"You chosen to do nothing with images.\")\n",
        "                else:\n",
        "                  move_img = 0\n",
        "                  print(\"\\n You chosen to copy sorted amber images.\")\n",
        "\n",
        "                break \n",
        "\n",
        "            orig_img_loc=str(input(f\"Enter from where to copy images to new location: (Opt. 1: {binary_image_save_location} ) (Opt. 2: {binary_image_save_location_orig} )\\n\"))\n",
        "            if orig_img_loc == \"\" or orig_img_loc == \"1\":\n",
        "              orig_img_loc = binary_image_save_location\n",
        "\n",
        "            elif orig_img_loc == \"2\":\n",
        "              orig_img_loc = binary_image_save_location_orig\n",
        "\n",
        "            clusteded_d_folder=str(input(f\"Enter where to save new Clustered data: (Opt1. : {sorted_image_loc} ) (Opt2. : {sorted_image_loc_orig} )\\n\"))\n",
        "            if clusteded_d_folder == \"\" or clusteded_d_folder == \"1\":\n",
        "              clusteded_d_folder = sorted_image_loc\n",
        "\n",
        "            elif clusteded_d_folder == \"2\":\n",
        "              clusteded_d_folder = sorted_image_loc_orig\n",
        "            \n",
        "            model_loc_folder=str(input(f\"Enter from where to read SOM Model or leave empty field for default Opt. 1. ( Opt. 1: {kmean_model_loc} )  (Opt. 2:  )\\n\")) # K-Mean-MODEL\n",
        "            if model_loc_folder == \"\" or model_loc_folder == \"1\":\n",
        "              model_loc_folder = kmean_model_loc\n",
        "            \n",
        "            while True:\n",
        "              try:\n",
        "                  relearn_query =int(input(\"Enter 0 - to create new SOM model, or 1 - To reuse existing SOM model. (default 0) \\n \"))\n",
        "              except ValueError:\n",
        "                  relearn_query = 0\n",
        "                  print(\"\\n You chosen to create new machine learning model.\")\n",
        "                  break\n",
        "                  continue\n",
        "\n",
        "              else:\n",
        "                  if relearn_query == 1:\n",
        "                    print(\"You chosen to reuse existing k-mean machine learning model.\")\n",
        "                  else:\n",
        "                    relearn_query = 0\n",
        "                    print(\"\\n You chosen to create new machine learning model.\")\n",
        "                  break\n",
        "\n",
        "            operation6_loadcsv_SOM(csv_folder, clusteded_d_folder, orig_img_loc, relearn_query, model_loc_folder, move_images = move_img)\n",
        "\n",
        "      elif pasirinktaOperacija == 8:\n",
        "          n_clusters = 1\n",
        "          csv_folder=str(input(f\"Enter from where to read CSV  (or leave empty field for default: Opt. 1: {csv_save_loc_one} )  ( Opt. 2: {csv_save_loc_group} )\\n\\\n",
        "                         #                               (Opt. 3: {csv_save_loc_one_orig} )  ( Opt. 4: {csv_save_loc_group_orig} )\\n\"))\n",
        "          if csv_folder == \"\" or csv_folder == \"1\":\n",
        "            csv_folder = csv_save_loc_one\n",
        "\n",
        "          elif  csv_folder == \"2\" :\n",
        "            csv_folder = csv_save_loc_group\n",
        "\n",
        "          elif  csv_folder == \"3\" :\n",
        "            csv_folder = csv_save_loc_one_orig\n",
        "\n",
        "          elif  csv_folder == \"4\" :\n",
        "            csv_folder = csv_save_loc_group_orig\n",
        "\n",
        "\n",
        "          csv_folder2=str(input(f\"Enter from where to read CSV  (or leave empty field for default: Opt. 1: {csv_save_loc_one} )  ( Opt. 2: {csv_save_loc_group} )\\n\\\n",
        "                             #                           (Opt. 3: {csv_save_loc_one_orig} )  ( Opt. 4: {csv_save_loc_group_orig} )\\n\"))\n",
        "          if csv_folder2 == \"\" or csv_folder2 == \"1\":\n",
        "            csv_folder2 = csv_save_loc_one\n",
        "\n",
        "          elif  csv_folder2 == \"2\" :\n",
        "            csv_folder2 = csv_save_loc_group\n",
        "\n",
        "          elif  csv_folder2 == \"3\" :\n",
        "            csv_folder2 = csv_save_loc_one_orig\n",
        "\n",
        "          elif  csv_folder2 == \"4\" :\n",
        "            csv_folder2 = csv_save_loc_group_orig\n",
        "\n",
        "          while True:\n",
        "            try:\n",
        "                move_img =int(1)\n",
        "            except ValueError:\n",
        "                move_img = 0\n",
        "                print(\"\\n You chosen to copy sorted amber images.\")\n",
        "                break\n",
        "                continue\n",
        "            else:\n",
        "              if move_img == 1:\n",
        "                print(\"You chosen to do nothing with images.\")\n",
        "              else:\n",
        "                move_img = 0\n",
        "                print(\"\\n You chosen to copy sorted amber images.\")\n",
        "\n",
        "              break \n",
        "\n",
        "          orig_img_loc=str(1)#input(f\"Enter from where to copy images to new location: (Opt. 1: {binary_image_save_location} ) (Opt. 2: {binary_image_save_location_orig} )\\n\"))\n",
        "          if orig_img_loc == \"\" or orig_img_loc == \"1\":\n",
        "            orig_img_loc = binary_image_save_location\n",
        "          elif orig_img_loc == \"2\":\n",
        "            orig_img_loc = binary_image_save_location_orig\n",
        "\n",
        "          clusteded_d_folder=str(1)#input(f\"Enter where to save new Clustered data: (Opt1. : {sorted_image_loc} ) (Opt2. : {sorted_image_loc_orig} )\\n\"))\n",
        "          if clusteded_d_folder == \"\" or clusteded_d_folder == \"1\":\n",
        "            clusteded_d_folder = sorted_image_loc\n",
        "          elif clusteded_d_folder == \"2\":\n",
        "            clusteded_d_folder = sorted_image_loc_orig\n",
        "          \n",
        "          model_loc_folder=str(1)#input(f\"Enter from where to read Kmean Model or leave empty field for default Opt. 1. ( Opt. 1: {kmean_model_loc} )  (Opt. 2:  )\\n\")) # K-Mean-MODEL\n",
        "          if model_loc_folder == \"\" or model_loc_folder == \"1\":\n",
        "            model_loc_folder = kmean_model_loc\n",
        "          \n",
        "          while True:\n",
        "            try:\n",
        "                relearn_query =int(0)#input(\"Enter 0 - to create new k-mean model, or 1 - To reuse existing k-mean model. (default 0) \\n \"))\n",
        "            except ValueError:\n",
        "                relearn_query = 0\n",
        "                print(\"\\n You chosen to create new machine learning model.\")\n",
        "                break\n",
        "                continue\n",
        "            else:\n",
        "                if relearn_query == 1:\n",
        "                  print(\"You chosen to reuse existing k-mean machine learning model.\")\n",
        "                else:\n",
        "                  relearn_query = 0\n",
        "                  print(\"\\n You chosen to create new machine learning model.\")\n",
        "                break \n",
        "\n",
        "          crossValidation(csv_folder, csv_folder2, clusteded_d_folder, orig_img_loc, relearn_query, model_loc_folder, move_images = move_img)\n",
        "\n",
        "      print(\"\\n\\n 1 - Reduce size of raw images;\")\n",
        "      print(\" 2 - Rename all images in pattern;\")\n",
        "      print(\" 3 - Convert raw images to BINARY/Greyscale images;\")\n",
        "      print(\" 4 - Create new Data Structure from binary images;\")\n",
        "      print(\" 5 - Sort Ambers - Data Structure CSV, with K-Means;\")\n",
        "      print(\" 6 - Display data structure in Correlation table;\")\n",
        "      print(\" 7 - Sort Ambers - Data Structure CSV, with SOM;\")\n",
        "      print(\" 0 - Exit\")\n",
        "\n",
        "      time.sleep(1)\n",
        "\n",
        "      while True:\n",
        "          try:\n",
        "              pasirinktaOperacija = int(input(\"What operation you want to do next?\\n  \")) \n",
        "          except ValueError:\n",
        "              print(\"You entered not a number! Try again.\")\n",
        "              continue\n",
        "          else:\n",
        "              break \n",
        "\n",
        "  print(\"Exiting . . .\")\n",
        "\n",
        "\n",
        "\n",
        "def crossValidation(csv_folder, csv_folder2 , cluster_loc = sorted_image_loc ,image_loc = binary_image_save_location, relearn_query = 0,  model_loc_folder = kmean_model_loc, normalization = 0, move_images = 0):\n",
        "  testi = True\n",
        "  try:\n",
        "    amber_csv_data1 = pd.read_csv(csv_folder) \n",
        "  except FileNotFoundError:\n",
        "    testi = False\n",
        "    print(f\"   !!! Alert !!!\\n   Wrong CSV location\\n   !!! Alert !!!\")\n",
        "\n",
        "  try:\n",
        "    amber_csv_data2 = pd.read_csv(csv_folder2) \n",
        "  except FileNotFoundError:\n",
        "    testi = False\n",
        "    print(f\"   !!! Alert !!!\\n   Wrong CSV location\\n   !!! Alert !!!\")\n",
        "\n",
        "  amber_csv_data = pd.concat([amber_csv_data1, amber_csv_data2])\n",
        "\n",
        "  if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "    try:\n",
        "      os.makedirs(os.path.dirname(cluster_loc))\n",
        "    except FileNotFoundError:\n",
        "      print(\"Wrong Clustered nuotrauka save location\")\n",
        "      testi = False\n",
        "\n",
        "  if not os.path.exists(os.path.dirname(cluster_loc)):\n",
        "    try:\n",
        "      aplankaloSarasas = os.listdir(image_loc)\n",
        "    except FileNotFoundError:\n",
        "      print(\"Wrong original nuotrauka reading location\")\n",
        "      testi = False\n",
        "\n",
        "  if testi:\n",
        "    while True:\n",
        "      try:\n",
        "          n_klasteriuDydis=int(input(\"Enter N cluster size for Kmean\\n \"))\n",
        "          if n_klasteriuDydis < 2 or n_klasteriuDydis >= len(amber_csv_data):\n",
        "            print(f\" cluster size should be: 2 <= n and n >= {len(amber_csv_data)}\")\n",
        "            continue\n",
        "\n",
        "      except ValueError:\n",
        "          print(\"You entered not a number! Try again.\")\n",
        "          continue\n",
        "\n",
        "      else:\n",
        "          break \n",
        "    \n",
        "    amber_csv_data.info()\n",
        "        \n",
        "    while True:\n",
        "      try:\n",
        "          t1 = str(\"\")#input(\"Enter DataStruct end limiter ( or leave empty for default colums )\\n \"))\n",
        "          if t1 == \"\" and len(amber_csv_data.columns) <= 23:\n",
        "            t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\")\n",
        "\n",
        "          elif t1 == \"\" and  len(amber_csv_data.columns) > 25:\n",
        "            t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\")\n",
        "\n",
        "      except ValueError:\n",
        "          if t1 == \"\" and  len(amber_csv_data.columns) <= 23:\n",
        "            t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19\")\n",
        "\n",
        "          elif t1 == \"\" and  len(amber_csv_data.columns) > 25:\n",
        "            t1 = str(\"3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67\")\n",
        "\n",
        "          else:\n",
        "            print(\"You entered not a number! Try again.\")\n",
        "            continue\n",
        "      else:\n",
        "          break \n",
        "    \n",
        "    columnsInput = list(map(converter,t1.split()))\n",
        "\n",
        "    if len(columnsInput) > 1 and amber_csv_data.columns.values.tolist()[columnsInput[0]] != 'CDF':\n",
        "\n",
        "      map_s = map(converter,t1.split())\n",
        "      map_s = [x for x in map_s if x >= 0 and x <= len(amber_csv_data.columns)]\n",
        "      s_copy = amber_csv_data.iloc[:, list(map_s)]\n",
        "      columnNames = s_copy.columns.values.tolist()\n",
        "\n",
        "      for dropNames in [string for string in columnNames if 'amber_cnt' in string or 'chaincode' in string or 'amber_picture' in string or 'amber_chain' in string or 'CDF' in string or 'major_axis_coordinates' in string or 'Filename' in string or 'amber_cnt' in string]:\n",
        "        s_copy = s_copy.drop([dropNames],axis = 1)\n",
        "      \n",
        "      if len(s_copy.columns) >= 1:\n",
        "        s_copy = s_copy.infer_objects()\n",
        "\n",
        "        kaipKopija = amber_csv_data.copy()\n",
        "\n",
        "        if relearn_query == 0:\n",
        "          smin = [];\n",
        "          smax = [];\n",
        "          for column in s_copy.columns:\n",
        "            smin.append(s_copy[column].min())\n",
        "            smax.append(s_copy[column].max())\n",
        "            s_copy[column] = (s_copy[column] -  s_copy[column].min() ) / (s_copy[column].max() -  s_copy[column].min())  \n",
        "          \n",
        "        elif relearn_query == 1:\n",
        "          smin = kmean_settings[2]\n",
        "          smax = kmean_settings[1]\n",
        "          i = 0\n",
        "          for column in s_copy.columns:\n",
        "            s_copy[column] = (s_copy[column] - smin[i]) / (smax[i] - smin[i])    \n",
        "            i += 1\n",
        "                  \n",
        "        X = s_copy.iloc[:, :].values\n",
        "\n",
        "        if len(X) == 0:\n",
        "          print(f\"   !!! Alert !!!\\n   Wrong file or amount of values is too low \\n   !!! Alert !!!\")\n",
        "\n",
        "        elif n_klasteriuDydis < len(X) or n_klasteriuDydis > 2:\n",
        "\n",
        "          scores = []\n",
        "          cv = KFold(n_splits=4, random_state=42, shuffle=True)\n",
        "          for train_index, test_index in cv.split(X):\n",
        "            kaipKopija = amber_csv_data.iloc[test_index[0]:test_index[-1]+1]\n",
        "            print(\"Train Index: \", train_index, \"\\n\")\n",
        "            print(\"Test Index: \", test_index)\n",
        "\n",
        "            X_train, X_test = X[train_index], X[test_index]\n",
        "            joined_dataxy = np.concatenate((X_train, X_test), axis=0)\n",
        "\n",
        "            amber_csv_data\n",
        "            ###\n",
        "            kVidurkiai = KMeans(n_clusters = n_klasteriuDydis)\n",
        "            x_kmeans_train = kVidurkiai.fit_predict(X_train)\n",
        "            yKvidurkiai = kVidurkiai.fit_predict(X_test)\n",
        "\n",
        "            joined_xy = np.append(x_kmeans_train, yKvidurkiai)\n",
        "           \n",
        "            ############################################\n",
        "            # Silhouette \n",
        "\n",
        "            print(\"\\n\\nThis Silhouette coefficient dimension tells, how points in one cluster are far away from another cluster;\", \"\\nThe silhouette coefficient of whole cluster is the average of all clusters silhouette coefficients, the value can differ between [-1,1];\")\n",
        "            print(\" - A value close to coefficient +1 indicates that the clusters are far from each other\")\n",
        "            print(\" - A value close to coefficient  0 indicates that the clusters are close to each other and they might overlap\")\n",
        "            print(\" - A value close to coefficient -1 indicates that certain points have been assigned incorrectly, which mignt be not for that cluster.\\n\")\n",
        "           \n",
        "            # Apskaiciuojami siluetai sio pavyzdzio\n",
        "\n",
        "            y_apatinis = 10\n",
        "\n",
        "           \n",
        "            siluetoVidurkis = siluetoTaskai(X_test, yKvidurkiai)\n",
        "            pavyzdzioSiluetoReiksmes = silhouette_samples(X_test, yKvidurkiai)\n",
        "            means = yKvidurkiai\n",
        "\n",
        "            print(\"For n_clusters =\", n_klasteriuDydis,\n",
        "                  \"The average silhouette score is: \", siluetoVidurkis,\" (marked in red dashed line)\")\n",
        "\n",
        "            for i in range(n_klasteriuDydis):\n",
        "                # Sumuokite pavyzdzius, priklausančius silueto \n",
        "                # klasteriam juos surusiuojant\n",
        "\n",
        "                ith_klasteriopavyzdzioSiluetoReiksmes = \\\n",
        "                pavyzdzioSiluetoReiksmes[means == i]\n",
        "\n",
        "                ith_klasteriopavyzdzioSiluetoReiksmes.sort()\n",
        "\n",
        "                klasterioDydis_i = ith_klasteriopavyzdzioSiluetoReiksmes.shape[0]\n",
        "                y_virsutinis = y_apatinis + klasterioDydis_i\n",
        "\n",
        "                color = cm.nipy_spectral(float(i) / n_klasteriuDydis)\n",
        "                plt.fill_betweenx(np.arange(y_apatinis, y_virsutinis),\n",
        "                                  0, ith_klasteriopavyzdzioSiluetoReiksmes,\n",
        "                                  facecolor=color, edgecolor=color, alpha=0.7)\n",
        "\n",
        "                # suzymime klasterius\n",
        "                plt.text(-0.05, y_apatinis + 0.5 * klasterioDydis_i, str(i))\n",
        "\n",
        "                # apskaiciuojamas y apatinis kitam plot\n",
        "                y_apatinis = y_virsutinis + 10 \n",
        "\n",
        "            plt.xlabel(\"The silhouette coefficient values\")\n",
        "            plt.ylabel(\"Cluster label\")\n",
        "\n",
        "            # Vertikali linija vidutiniam visų verčių silueto balui\n",
        "            plt.axvline(x = siluetoVidurkis, color=\"red\", linestyle=\"--\")\n",
        "\n",
        "            plt.yticks([]) \n",
        "            plt.xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
        "\n",
        "            plt.suptitle((\"Silhouette analysis of KMeans clustering \"\n",
        "                          \"with n_clusters = %d\" % n_klasteriuDydis),\n",
        "                        fontsize=15, fontweight='bold')\n",
        "            plt.show()\n",
        "\n",
        "            ############################################\n",
        "            # alkūnės metodas\n",
        "            if len(X) >= n_klasteriuDydis:\n",
        "              distortions = []\n",
        "              if len(X) >= n_klasteriuDydis + n_klasteriuDydis:\n",
        "                K = range(1, (n_klasteriuDydis + n_klasteriuDydis ))\n",
        "              else: \n",
        "                K = range(1, (n_klasteriuDydis ))\n",
        "\n",
        "              print(\"\\n\\nInertia graph. Which shows how far away are clusters between each other;\", \"\\nIt is suggested to avoid over-clustering and to choose the number of clusters that is close to the rise of the inertia curve;\\n\")\n",
        "              distortions = []\n",
        "\n",
        "              for k in K:\n",
        "                  kVidurkiuModelis = KMeans(n_clusters = k)\n",
        "                  \n",
        "                  kVidurkiuModelis.fit(X_train)\n",
        "                  kVidurkiuModelis.fit(X_test)\n",
        "\n",
        "                  distortions.append(kVidurkiuModelis.inertia_)\n",
        "\n",
        "              plt.figure(figsize=(8,4))\n",
        "              plt.plot(K, distortions, 'bx-')\n",
        "              plt.xlabel('k - amount of clusters')\n",
        "              plt.ylabel('Inertia')\n",
        "              plt.title('The Elbow Method, which shows the optimal k')\n",
        "              plt.show()\n",
        "              \n",
        "            else:\n",
        "              print(\"Cant display Elbow method analysis, the amount of samples is too low\")\n",
        "          ############################################\n",
        "        else:\n",
        "          print(f\"   !!! Alert !!!\\n   You need to change N - cluster size [2,{len(X)}]\\n   !!! Alert !!!\")\n",
        "      else:\n",
        "        print(f\"   !!! Alert !!!\\n   You need to enter more avaible values\\n {len(s_copy.columns)}  !!! Alert !!!\")\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dG1M8fkChlcV"
      },
      "source": [
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
